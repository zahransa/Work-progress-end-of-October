@article{TiconaUltimo,
author = {Ticona, Regina and Tekli, Joe and Dongo, Irvin and Guzman, Renato and Chbeir, Richard},
keywords = {ical redundancies,log-,normalization process,physical disparities,rdf graph,rdf serialization},
title = {{Toward RDF Normalization}},
url = {http://arxiv.org/abs/1707.03602},
year = {2017}
}

@misc{w3:2004:w3c,
   author = {w3c},
   title = {Resource Description Framework (RDF):Concepts and Abstract Syntax},
   year = {2004},
   url = {URL{https://www.w3.org/TR/rdf-concepts/}},
   note = "[Web; accedido el 06-10-2018]"
 }



@article{Pappas2017,
author = {Pappas, Alexandros and Troullinou, Georgia and Roussakis, Giannis and B, Haridimos Kondylakis and Plexousakis, Dimitris},
doi = {10.1007/978-3-319-58068-5},
file = {:D$\backslash$:/Mendeley/Exploring Importance Measures for summarizing RDF.pdf:pdf},
isbn = {978-3-319-58067-8},
keywords = {edge bases,graph theory,rdf,s knowl-,schema summary,semantic summaries},
pages = {387--403},
title = {{The Semantic Web}},
url = {http://link.springer.com/10.1007/978-3-319-58068-5},
volume = {10249},
year = {2017}
}
@article{Cheng2012,
abstract = {When searching for RDF vocabularies, users often feel hindered by the lengthy description of a retrieved vocabulary from judging its relevance. A natural strategy for dealing with this issue is to generate a summary of the vocabulary description that compactly carries its main theme and reveals its relevance to the user's information need. In this paper, we present a new solution to this problem of vocabulary summarization, which has been defined as ranking and selecting RDF sentences in our previous work. Firstly, we propose a novel bipartite graph representation of vocabulary description, on which we carry out a stochastic analysis of a random surfer's behavior, from which we derive a new centrality measure for RDF sentences called BipRank. Further, we improve it by investigating the patterns of RDF sentences and employing their statistical features. Then, we combine BipRank with query relevance and cohesion metrics into an aggregate objective function to be optimized for the selection of RDF sentences. Our experiments on real-world vocabularies demonstrate the superiority of our approach to the baseline, and also validate its scalability in practice.},
author = {Cheng, Gong and Ji, Feng and Luo, Shengmei and Ge, Weiyi and Qu, Yuzhong},
doi = {10.1007/978-3-642-29923-0_15},
file = {:D$\backslash$:/Mendeley/BipRank Ranking and Summarizing RDF Vocabulary Descriptions.pdf:pdf},
isbn = {9783642299223},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Cohesion,query relevance,random surfer model,ranking,vocabulary summarization},
pages = {226--241},
title = {{BipRank: Ranking and summarizing RDF vocabulary descriptions}},
volume = {7185 LNCS},
year = {2012}
}
@article{Kawtrakul2014,
abstract = {Recently, a large number of sensors have been deployed in urban areas, and they can be used for several purposes toward safe and secure urban life. Cost effective sensing and controlling for human activities are becoming possible. As pervasive sensing progresses, Human centric Cyber Physical System (HCPS) will receive much attention where effects of human activities are taken into consideration for designing and developing CPS based social systems. In this paper, we focus on safe and secure urban life and present two case studies: (a) classification of patients in emergency hospitals and (b) estimation of urban pedestrian flows. We also present our testing environment for HCPS. {\textcopyright} Springer-Verlag Berlin Heidelberg 2013.},
author = {Kawtrakul, Asanee and Laurent, Dominique and Spyratos, Nicolas and Tanaka, Yuzuru},
doi = {10.1007/978-3-319-08732-0},
file = {:D$\backslash$:/Mendeley/RDF Graph Summarization based on appoximate patterns.pdf:pdf},
isbn = {9783319087313},
issn = {18650929},
journal = {Communications in Computer and Information Science},
keywords = {approximate patterns,federated query,linked open data,query,rdf graph summary},
pages = {69--87},
title = {{Information search, integration, and personalization}},
volume = {421 CCIS},
year = {2014}
}
@article{Manolescu2018a,
author = {Manolescu, Ioana},
file = {:D$\backslash$:/Mendeley/Structural Summarization of Semantic Graphs.pdf:pdf},
keywords = {Semantic Web, graph summaries, RDF, quotient graph},
title = {{Structural Summarization of Semantic Graphs Ioana Manolescu To cite this version : HAL Id : hal-01808737 Structural Summarization of Semantic Graphs}},
year = {2018}
}
@article{Zhang2007,
abstract = {Ontology summarization is very important to quick under- standing and selection of ontologies. In this paper, we study extractive summarization of ontology. We propose a notion of RDF sentence as the basic unit of summarization. An RDF Sentence Graph is proposed to characterize the links between RDF sentences derived from a given ontology. The salience of each RDF sentence is assessed in terms of its ``cen- trality'' in the graph. We propose to summarize an ontology by extracting a set of salient RDF sentences according to a re-ranking strategy. We compare several measurements in assessing the salience of RDF sentences and give an over- all evaluation of experiment results, which shows that our approach to ontology summarization is feasible.},
author = {Zhang, Xiang and Cheng, Gong and Qu, Yuzhong},
doi = {10.1145/1242572.1242668},
file = {:D$\backslash$:/Mendeley/1 Ontology Summarization Based on RDF Sentence Graph.pdf:pdf},
isbn = {9781595936547},
issn = {08963207},
journal = {Proceedings of the 16th international conference on World Wide Web  - WWW '07},
keywords = {centrality,graph,ontology summarization,rdf sentence,re-ranking},
pages = {707},
title = {{Ontology summarization based on rdf sentence graph}},
url = {http://portal.acm.org/citation.cfm?doid=1242572.1242668},
year = {2007}
}
@article{Peroni2008,
abstract = {In this paper we address the issue of identifying the concepts in an ontology, which best summarize what the ontology is about. Our approach combines a number of criteria, drawn from cognitive science, network topology, and lexical statistics. In the paper we show two versions of our algorithm, which have been evaluated against the results produced by human experts. We report that the latest version of the algorithm performs very well, exhibiting an excellent degree of correlation with the choices of the experts. While the generation of automatic methods for ontology summarization is an interesting research issue in itself, the work described here also provides a basis for novel approaches to a variety of ontology engineering tasks, including ontology matching, automatic classification, ontology modularization, and ontology evaluation.},
author = {Peroni, Silvio and Motta, Enrico and D'Aquin, Mathieu},
doi = {10.1007/978-3-540-89704-0_17},
file = {:D$\backslash$:/Mendeley/Coverage (Co).pdf:pdf},
isbn = {3540897038},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Cognitive science,Key concepts,Natural categories,Ontology,Ontology summarization,Semantic web},
pages = {242--256},
title = {{Identifying key concepts in an ontology, through the integration of cognitive principles with statistical and topological measures}},
volume = {5367 LNCS},
year = {2008}
}
@phdthesis{Fan2017,
author = {Fan, Zhengjie and Fan, Zhengjie and Pattern, Concise and Data, R D F and Interlinking, Sets and Universit{\'{e}}, D B and E, Docteur D E L Universit and Fan, Zhengjie},
file = {:D$\backslash$:/Mendeley/Thesis Concise Pattern Learning for RDF Data Sets.pdf:pdf},
title = {{Concise Pattern Learning for RDF Data Sets Interlinking}},
year = {2017}
}
@article{,
file = {:D$\backslash$:/Mendeley/Semantic Search On Summarized RDF Triples.pdf:pdf},
keywords = {clustering,rdf graph,sparql,wordnet},
title = {{Semantic Search On Summarized RDF Triples}},
year = {2017}
}
@article{Basse2012,
author = {Basse, Adrien and Gandon, Fabien and Mirbel, Isabelle and Lo, Moussa},
file = {:D$\backslash$:/Mendeley/thesis Incremental characterization of RDF Triple Stores.pdf:pdf},
pages = {691201--2},
title = {{Incremental characterization of RDF Triple Stores}},
url = {https://hal.inria.fr/hal-00691201v2},
volume = {24},
year = {2012}
}
@article{Guzewicz2018,
abstract = {L'archive ouverte pluridisciplinaire HAL, est destin{\'{e}}e au d{\'{e}}p{\^{o}}t et {\`{a}} la diffusion de documents scientifiques de niveau recherche, publi{\'{e}}s ou non, {\'{e}}manant des {\'{e}}tablissements d'enseignement et de recherche fran{\c{c}}ais ou {\'{e}}trangers, des laboratoires publics ou priv{\'{e}}s. Abstractâ€”Summarization has been applied to RDF graphs to obtain a compact representation thereof, easier to grasp by human users. We present a new brand of quotient-based RDF graph summaries, whose main novelty is to summarize together RDF nodes belonging to the same type hierarchy. We argue that such summaries bring more useful information to users about the structure and semantics of an RDF graph.},
author = {Guzewicz, Pawe{\l} and Manolescu, Ioana},
doi = {10.1109/ICDEW.2018.00018},
file = {:D$\backslash$:/Mendeley/Quotient RDF Summaries Based on Type Hierarchies.pdf:pdf},
isbn = {9781538663066},
journal = {Proceedings - IEEE 34th International Conference on Data Engineering Workshops, ICDEW 2018},
keywords = {Hierarchies,Quotient,RDFgraph,Summaries,Types},
pages = {66--71},
title = {{Quotient RDF summaries based on type hierarchies}},
year = {2018}
}
@article{Zneika2016,
author = {Zneika, Mussab and Lucchese, Claudio and Vodislav, Dan and Kotzinos, Dimitris},
doi = {10.5441/002/edbt.2016.86},
file = {:D$\backslash$:/Mendeley/Summarizing Linked Data RDF Graphs Using appoximate graph pattern mining.pdf:pdf},
isbn = {9783893180707},
issn = {23672005},
journal = {Proc. 19th International Conference on Extending Database Technology},
keywords = {linked open data,query processing,rdf summarization},
pages = {684--685},
title = {{Summarizing Linked Data RDF Graphs Using Approximate Graph Pattern Mining}},
year = {2016}
}
@article{Bursztyn2014,
author = {Bursztyn, Damian and Goasdou{\'{e}}, Fran{\c{c}}ois and Manolescu, Ioana},
doi = {10.5441/002/edbt.2015.24},
file = {:D$\backslash$:/Mendeley/Optimizing Reformulation-based Query Answering in RDF.pdf:pdf},
isbn = {9783893180677},
journal = {18th International Conference on Extending Database Technology (EDBT)},
pages = {265--276},
title = {{Optimizing Reformulation-based Query Answering in RDF}},
year = {2014}
}
@article{Pouriyeh2018,
abstract = {Ontologies have been widely used in numerous and varied applications, e.g., to support data modeling, information integration, and knowledge management. With the increasing size of ontologies, ontology understanding, which is playing an important role in different tasks, is becoming more difficult. Consequently, ontology summarization, as a way to distill key information from an ontology and generate an abridged version to facilitate a better understanding, is getting growing attention. In this survey paper, we review existing ontology summarization techniques and focus mainly on graph-based methods, which represent an ontology as a graph and apply centrality-based and other measures to identify the most important elements of an ontology as its summary. After analyzing their strengths and weaknesses, we highlight a few potential directions for future research.},
archivePrefix = {arXiv},
arxivId = {1805.06051},
author = {Pouriyeh, Seyedamin and Allahyari, Mehdi and Liu, Qingxia and Cheng, Gong and Arabnia, Hamid Reza and Qu, Yuzhong and Kochut, Krys},
eprint = {1805.06051},
file = {:D$\backslash$:/Mendeley/Graph-based Ontology Summarization A Survey.pdf:pdf},
keywords = {ontology,ontology summarization,rdf,s},
pages = {1--15},
title = {{Graph-based Ontology Summarization: A Survey}},
url = {http://arxiv.org/abs/1805.06051},
year = {2018}
}
@article{Tzitzikas2007,
abstract = {Ranking is a ubiquitous requirement whenever we confront a large collection of atomic or interrelated artifacts. This paper elaborates on this issue for the case of RDF schemas. Specifically, several metrics for evaluating automatic methods for ranking schema elements are proposed and discussed. Subsequently the creation of a test collection for evaluating such methods is described, upon which several ranking methods (from simple to more sophisticated) for RDF schemas are evaluated. This formal way for evaluating ranking methods, apart from yielding credible and repeatable results, gave us some interesting insights to the problem. Finally, our experiences from exploiting these ranking methods for visualizing R-DF schemas, specifically for deriving and visualizing top-k schema subgraphs, are reported. {\textcopyright} J.UCS.},
author = {Tzitzikas, Y. and Kotzinos, D. and Theoharis, Y.},
file = {:D$\backslash$:/Mendeley/On Ranking RDF Schema Elements.pdf:pdf},
issn = {09486968 (ISSN)},
journal = {Journal of Universal Computer Science},
keywords = {schema ranking,schema visualization,semantic web},
number = {12},
pages = {1854--1880},
title = {{On ranking RDF schema elements (and its application in visualization)}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-40849134188{\&}partnerID=40{\&}md5=11f36c1ed93169bec179b20aaf0a2555},
volume = {13},
year = {2007}
}
@article{Cheng2012a,
abstract = {When searching for RDF vocabularies, users often feel hindered by the lengthy description of a retrieved vocabulary from judging its relevance. A natural strategy for dealing with this issue is to generate a summary of the vocabulary description that compactly carries its main theme and reveals its relevance to the user's information need. In this paper, we present a new solution to this problem of vocabulary summarization, which has been defined as ranking and selecting RDF sentences in our previous work. Firstly, we propose a novel bipartite graph representation of vocabulary description, on which we carry out a stochastic analysis of a random surfer's behavior, from which we derive a new centrality measure for RDF sentences called BipRank. Further, we improve it by investigating the patterns of RDF sentences and employing their statistical features. Then, we combine BipRank with query relevance and cohesion metrics into an aggregate objective function to be optimized for the selection of RDF sentences. Our experiments on real-world vocabularies demonstrate the superiority of our approach to the baseline, and also validate its scalability in practice.},
author = {Cheng, Gong and Ji, Feng and Luo, Shengmei and Ge, Weiyi and Qu, Yuzhong},
doi = {10.1007/978-3-642-29923-0_15},
file = {:D$\backslash$:/Mendeley/leerProblem Statement.pdf:pdf},
isbn = {9783642299223},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Cohesion,query relevance,random surfer model,ranking,vocabulary summarization},
pages = {226--241},
title = {{BipRank: Ranking and summarizing RDF vocabulary descriptions}},
volume = {7185 LNCS},
year = {2012}
}
@article{Cheng2011,
abstract = {This poster proposes a novel approach for generating sum- maries for ontology search. Following previous work, we define ontology summarization as the problem of ranking and selecting RDF sentences, for which we examine three aspects. Firstly, to assess the salience of RDF sentences in an ontology, we devise a bipartite graph model for represent- ing the ontology and analyze random walks on this graph. Secondly, to reflect how an ontology is matched with user needs expressed via keyword queries, we incorporate query relevance into the selection of RDF sentences. Finally, to improve the unity of a summary, we optimize its cohesion in terms of the connections between constituent RDF sen- tences. We have implemented an online prototype system called Falcons Ontology Search.},
author = {Cheng, Gong and Ge, Weiyi and Qu, Yuzhong},
doi = {10.1145/1963192.1963207},
file = {:D$\backslash$:/Mendeley/Generating Summaries for Ontology Search.pdf:pdf},
isbn = {9781450306379},
journal = {Proceedings of the 20th international conference companion on World wide web - WWW '11},
keywords = {cohesion,ontology summarization,query relevance,random},
number = {1},
pages = {27},
title = {{Generating summaries for ontology search}},
url = {http://portal.acm.org/citation.cfm?doid=1963192.1963207},
year = {2011}
}
@article{Drumond2012,
abstract = {On RDF datasets, the truth values of triples are known when they are either explicitly stated or can be inferred using log-ical entailment. Due to the open world semantics of RDF, nothing can be said about the truth values of triples that are neither in the dataset nor can be logically inferred. By es-timating the truth values of such triples, one could discover new information from the database thus enabling to broaden the scope of queries to an RDF base that can be answered, support knowledge engineers in maintaining such knowledge bases or recommend users resources worth looking into for instance. In this paper, we present a new approach to pre-dict the truth values of any RDF triple. Our approach uses a 3-dimensional tensor representation of the RDF knowl-edge base and applies tensor factorization techniques that take open world semantics into account to predict new true triples given already observed ones. We report results of experiments on real world datasets comparing different ten-sor factorization models. Our empirical results indicate that our approach is highly successful in estimating triple truth values on incomplete RDF datasets.},
author = {Drumond, Lucas and Rendle, Steffen and Schmidt-Thieme, Lars},
doi = {10.1145/2245276.2245341},
file = {:D$\backslash$:/Mendeley/Predicting RDF Triples in Incomplete Knowledge Bases.pdf:pdf},
isbn = {9781450308571},
journal = {Proceedings of the 27th Annual ACM Symposium on Applied Computing - SAC '12},
pages = {326},
title = {{Predicting RDF triples in incomplete knowledge bases with tensor factorization}},
url = {http://dl.acm.org/citation.cfm?doid=2245276.2245341},
year = {2012}
}
@article{??ebiri??2015,
author = {??ebiri??, ??ejla and Goasdou??, Fran??ois and Manolescu, Ioana},
doi = {10.1007/978-3-319-20424-6_9},
file = {:D$\backslash$:/Mendeley/Query-Oriented Summarization of RDF Graph2.pdf:pdf},
isbn = {9783319204239},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {may},
pages = {87--91},
title = {{Query-Oriented summarization of RDF graphs}},
volume = {9147},
year = {2015}
}
@article{Zneika2018,
author = {Zneika, Mussab and Vodislav, Dan and Kotzinos, Dimitris and Metrics, Quality and Rdf, For and Summarization, Graph},
file = {:D$\backslash$:/Mendeley/Quality Metrics For RDF Graph Summarization.pdf:pdf},
keywords = {linked open data,quality framework,quality metrics,rdf query processing,rdf summarization},
title = {{Quality Metrics For RDF Graph Summarization}},
year = {2018}
}
@article{Su2014,
abstract = {Applying Semantic Web technologies to Internet of Things (IoT) enables smart applications and services in a variety of domains. However, the gap between semantic representations and data formats used in IoT devices introduces a challenge for utilizing semantics in IoT. Sensor Markup Language (SenML) is an emerging solution for representing device parameters and measurements. SenML is replacing proprietary data formats and is being accepted by more and more vendors. In this paper, we suggest a solution to transform SenML data into a standardized semantic model, Resource Description Framework (RDF). Such a transformation facilitates intelligent functions in IoT, including reasoning over sensor data and semantic interoperability among devices. We present a fishery IoT system to illustrate the usability of this approach and compare the resource consumptions of SenML against other alternatives. {\textcopyright} 2014 Published by Elsevier B.V.},
author = {Su, Xiang and Zhang, Hao and Riekki, Jukka and Ker{\"{a}}nen, Ari and Nurminen, Jukka K. and Du, Libin},
doi = {10.1016/j.procs.2014.05.417},
file = {:D$\backslash$:/Mendeley/Connecting IoT Sensors to Knowledge-Based Systems by transforming enML to RDF.pdf:pdf},
isbn = {18770509},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Inference,Media Types for Sensor Markup Language,RDF},
pages = {215--222},
title = {{Connecting IoT sensors to knowledge-based systems by transforming SenML to RDF}},
volume = {32},
year = {2014}
}
@article{,
file = {:D$\backslash$:/Mendeley/Validating RDF Data.pdf:pdf},
title = {{Validating RDF Data}}
}
@article{Hassad2017a,
author = {Hassad, Sara El},
doi = {10.1007/978-3-319-58068-5},
file = {:D$\backslash$:/Mendeley/THESES Learning Commonalities in RDF and SPARQL.pdf:pdf},
isbn = {9783319580685},
keywords = {least general generalization,rdf,rdf entailment,rdfs},
pages = {502--517},
title = {{Learning Commonalities in RDF}},
year = {2017}
}
@article{Ayvaz2017,
abstract = {The Semantic Web began to emerge as its standards and technologies developed rapidly in the recent years. The continuing development of Semantic Web technologies has facilitated publishing explicit semantics with data on the Web in RDF data model. This study proposes a semantic search framework to support efficient keyword-based semantic search on RDF data utilizing near neighbor explorations. The framework augments the search results with the resources in close proximity by utilizing the entity type semantics. Along with the search results, the system generates a relevance confidence score measuring the inferred semantic relatedness of returned entities based on the degree of similarity. Furthermore, the evaluations assessing the effectiveness of the framework and the accuracy of the results are presented.},
archivePrefix = {arXiv},
arxivId = {1707.03602},
author = {Ayvaz, Serkan and Aydar, Mehmet},
eprint = {1707.03602},
file = {:D$\backslash$:/Mendeley/Using RDF Summary Graph For Keyword-based Semantic Searches.pdf:pdf},
keywords = {form and widely used,in daily,queries are easier to},
title = {{Using RDF Summary Graph For Keyword-based Semantic Searches}},
url = {http://arxiv.org/abs/1707.03602},
year = {2017}
}
@article{Discipline2011a,
author = {Discipline, S T a P S and Cnu, Section and Vincent, Chaubet and Richard, Montoya and Nicolas, Forestier},
file = {:D$\backslash$:/Mendeley/THESES Towards RDF Normalization.pdf:pdf},
isbn = {4444444444444},
number = {July},
title = {{Universit{\'{e}} de pau et des pays de l'adour}},
year = {2011}
}
@article{Zliobaite2010,
abstract = {Concept drift refers to a non stationary learning problem over time. The training and the application data often mismatch in real life problems. In this report we present a context of concept drift problem 1. We focus on the issues relevant to adaptive training set formation. We present the framework and terminology, and formulate a global picture of concept drift learners design. We start with formalizing the framework for the concept drifting data in Section 1. In Section 2 we discuss the adaptivity mechanisms of the concept drift learners. In Section 3 we overview the principle mechanisms of concept drift learners. In this chapter we give a general picture of the available algorithms and categorize them based on their properties. Section 5 discusses the related research fields and Section 5 groups and presents major concept drift applications. This report is intended to give a bird's view of concept drift research field, provide a context of the research and position it within broad spectrum of research fields and applications.},
archivePrefix = {arXiv},
arxivId = {1010.4784},
author = {{\v{Z}}liobaitÄ—, IndrÄ—},
doi = {10.1002/sam},
eprint = {1010.4784},
file = {:D$\backslash$:/Mendeley/Summarizing and Understanding Large Graphs.pdf:pdf},
isbn = {9781634393973},
issn = {09574174},
keywords = {graph summarization,graph visualization,minimum description length},
number = {i},
pmid = {21824845},
title = {{Learning under Concept Drift: an Overview}},
url = {http://arxiv.org/abs/1010.4784},
year = {2010}
}
@article{Ticona-herrera,
author = {Ticona-herrera, Regina and Tekli, Joe and Dongo, Irvin and Guzman, Renato and Chbeir, Richard},
file = {:D$\backslash$:/Mendeley/Toward RDF Normalization.pdf:pdf},
keywords = {ical redundancies,log-,normalization process,physical disparities,rdf graph,rdf serialization},
title = {{Toward RDF Normalization}}
}
@article{Manolescu2018,
author = {Manolescu, Ioana},
file = {:D$\backslash$:/Mendeley/structural Summatization of Semantic Graphs.pdf:pdf},
keywords = {Semantic Web, graph summaries, RDF, quotient graph},
title = {{Structural Summarization of Semantic Graphs Ioana Manolescu To cite this version : HAL Id : hal-01808737 Structural Summarization of Semantic Graphs}},
year = {2018}
}
@article{Zhu2017,
abstract = {Sematch is an integrated framework for the development, evaluation and application of semantic similarity for Knowledge Graphs. The framework provides a number of similarity tools and datasets, and allows users to compute semantic similarity scores of concepts, words, and entities, as well as to interact with Knowledge Graphs through SPARQL queries. Sematch focuses on knowledge-based semantic similarity that relies on structural knowledge in a given taxonomy (e.g. depth, path length, least common subsumer), and statistical information contents. Researchers can use Sematch to develop and evaluate semantic similarity metrics and exploit these metrics in applications.},
author = {Zhu, Ganggao and Iglesias, Carlos A.},
doi = {10.1016/j.knosys.2017.05.021},
file = {:D$\backslash$:/Mendeley/Sematch Semantic similarity framework for Knowledge Graph.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Classification,Evaluation,Knowledge Graphs,Semantic similarity,Taxonomy},
pages = {30--32},
publisher = {Elsevier B.V.},
title = {{Sematch: Semantic similarity framework for Knowledge Graphs}},
volume = {130},
year = {2017}
}
@article{Hees2016a,
abstract = {Efficient usage of the knowledge provided by the Linked Data community is often hindered by the need for domain experts to formulate the right SPARQL queries to answer questions. For new questions they have to decide which datasets are suitable and in which terminology and modelling style to phrase the SPARQL query. In this work we present an evolutionary algorithm to help with this challenging task. Given a training list of source-target node-pair examples our algorithm can learn patterns (SPARQL queries) from a SPARQL endpoint. The learned patterns can be visualised to form the basis for further investigation, or they can be used to predict target nodes for new source nodes. Amongst others, we apply our algorithm to a dataset of several hundred human associations (such as "circle - square") to find patterns for them in DBpedia. We show the scalability of the algorithm by running it against a SPARQL endpoint loaded with {\textgreater} 7.9 billion triples. Further, we use the resulting SPARQL queries to mimic human associations with a Mean Average Precision (MAP) of 39.9 {\%} and a Recall@10 of 63.9 {\%}.},
archivePrefix = {arXiv},
arxivId = {1607.07249},
author = {Hees, J{\"{o}}rn and Bauer, Rouven and Folz, Joachim and Borth, Damian and Dengel, Andreas},
doi = {10.1007/978-3-319-49004-5_22},
eprint = {1607.07249},
file = {:D$\backslash$:/Mendeley/Hees et al. - 2016 - An evolutionary algorithm to learn SPARQL queries for source-target-pairs finding patterns for human associations i.pdf:pdf;:D$\backslash$:/Mendeley/Slides{\_}An Evolutionary Algorithm to Learn SPARQL.pdf:pdf},
isbn = {9783319490038},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {337--352},
title = {{An evolutionary algorithm to learn SPARQL queries for source-target-pairs finding patterns for human associations in DBpedia}},
volume = {10024 LNAI},
year = {2016}
}
@article{DeVries2015,
abstract = {In this paper we introduce a framework for learning from RDF data using graph kernels that count substructures in RDF graphs, which systematically covers most of the existing kernels previously defined and provides a number of new variants. Our definitions include fast kernel variants that are computed directly on the RDF graph. To improve the performance of these kernels we detail two strategies. The first strategy involves ignoring the vertex labels that have a low frequency among the instances. Our second strategy is to remove hubs to simplify the RDF graphs. We test our kernels in a number of classification experiments with real-world RDF datasets. Overall the kernels that count subtrees show the best performance. However, they are closely followed by simple bag of labels baseline kernels. The direct kernels substantially decrease computation time, while keeping performance the same. For the walks counting kernel this decrease in computation time is so large that it thereby becomes a computationally viable kernel to use. Ignoring low frequency labels improves the performance for all datasets. The hub removal algorithm increases performance on two out of three of our smaller datasets, but has little impact when used on our larger datasets.},
author = {{De Vries}, Gerben Klaas Dirk and {De Rooij}, Steven},
doi = {10.1016/j.websem.2015.08.002},
file = {:D$\backslash$:/Mendeley/Substructure counting graph kernels for machine learning from RDF.pdf:pdf},
issn = {15708268},
journal = {Journal of Web Semantics},
keywords = {Graph kernels,Hub removal,Machine learning for RDF,Weisfeiler-Lehman},
pages = {71--84},
publisher = {Elsevier B.V.},
title = {{Substructure counting graph kernels for machine learning from RDF data}},
url = {http://dx.doi.org/10.1016/j.websem.2015.08.002},
volume = {35},
year = {2015}
}
@article{Xylogiannopoulos,
author = {Xylogiannopoulos, Konstantinos F and Karampelas, Panagiotis and Alhajj, Reda},
file = {:D$\backslash$:/Mendeley/Dynamic Pattern Detection for Big Data stream analytics.pdf:pdf},
isbn = {9783319781969},
keywords = {arpad,big data,data stream,lerp-rsa,pattern detection},
title = {{Dynamic Pattern Detection for Big Data Stream Analytics}}
}
@article{Potoniec2016,
author = {Potoniec, Jedrzej},
file = {:D$\backslash$:/Mendeley/An On-Line Learning to Query System.pdf:pdf},
issn = {16130073},
journal = {CEUR Workshop Proceedings},
title = {{An on-line learning to query system}},
volume = {1690},
year = {2016}
}
@article{Hayes2004,
abstract = {RDF Graphs are sets of assertions in the form of subject- predicate-object triples of information resources. Although for simple examples they can be understood intuitively as directed labeled graphs, this representation does not scale well for more complex cases, particu- larly regarding the central notion of connectivity of resources. We argue in this paper that there is need for an intermediate repre- sentation of RDF to enable the application of well-established methods from graph theory. We introduce the concept of RDF Bipartite Graph and show its advantages as intermediate model between the abstract triple syntax and data structures used by applications. In the light of this model we explore the issues of transformation costs, data/schema- structure, and the notion of RDF connectivity.},
author = {Hayes, Jonathan and Gutierrez, Claudio},
doi = {10.1007/978-3-540-30475-3_5},
file = {:D$\backslash$:/Mendeley/Bipartite graphs as intermediate model for RDF.pdf:pdf},
isbn = {978-3-540-23798-3},
issn = {03029743},
journal = {The Semantic Web â€“ ISWC 2004},
keywords = {bipartite graph,rdf databases,rdf graph,rdf model},
number = {3298},
pages = {47--61},
title = {{Bipartite Graphs as Intermediate Model for RDF}},
year = {2004}
}
@article{Ayvaz2015,
abstract = {{\textcopyright} 2015 IEEE. The structured data available in the semantic web have been rapidly increasing with the contribution of linked open data and other similar community initiatives in recent years. Thus, searching and processing large data have become more challenging. Building a summary graph can help reduce the computational complexity and query time in semantic searches by providing an intermediate index structure which contains entity type classes and relations between them. In the current study, we propose an algorithm for discovering the types of entities in RDF data and for building a summary graph structure for faster computational processing.},
author = {Ayvaz, Serkan and Aydar, Mehmet and Melton, Austin},
doi = {10.1109/COMPSAC.2015.107},
file = {:D$\backslash$:/Mendeley/Building Summary Graphs of RDF Data in Semantic web.pdf:pdf},
isbn = {9781467365635},
issn = {07303157},
journal = {Proceedings - International Computer Software and Applications Conference},
keywords = {Graph Summarization,RDF,Semantic Web},
pages = {686--691},
title = {{Building Summary Graphs of RDF Data in Semantic Web}},
volume = {2},
year = {2015}
}
@article{Arnaout2018,
abstract = {RDF knowledge graphs are typically searched using triple-pattern queries. Often, triple-pattern queries will return too many or too few results, making it difficult for users to find relevant answers to their information needs. To remedy this, we propose a general framework for effective searching of RDF knowledge graphs. Our framework extends both the searched knowledge graph and triple-pattern queries with keywords to allow users to form a wider range of queries. In addition, it provides result ranking based on statistical machine translation, and performs automatic query relaxation to improve query recall. Finally, we also define a notion of result diversity in the setting of RDF data and provide mechanisms to diversify RDF search results using Maximal Marginal Relevance. We evaluate the effectiveness of our retrieval framework using various carefully-designed user studies on DBpedia, a large and real-world RDF knowledge graph.},
author = {Arnaout, Hiba and Elbassuoni, Shady},
doi = {10.1016/j.websem.2017.12.001},
file = {:D$\backslash$:/Mendeley/Effective searching of RDF knowledge graphs.pdf:pdf},
issn = {15708268},
journal = {Journal of Web Semantics},
keywords = {Diversity,RDF,Ranking,Relaxation},
pages = {1--21},
publisher = {Elsevier B.V.},
title = {{Effective searching of RDF knowledge graphs}},
volume = {48},
year = {2018}
}
@article{Cebiric2017,
author = {{\v{C}}ebiri{\'{c}}, {\v{S}}ejla and Goasdou{\'{e}}, Fran{\c{c}}ois and Manolescu, Ioana},
file = {:D$\backslash$:/Mendeley/A Framework for Efficient Representative summarization of RDF Graphs.pdf:pdf},
issn = {16130073},
journal = {CEUR Workshop Proceedings},
title = {{A framework for efficient representative summarization of RDF graphs}},
volume = {1963},
year = {2017}
}
@article{Aydar2015,
abstract = {In this current study, we use graph localities and neighbor-hood similarity to enhance the summary graph generation approach for building a summary graph structure for intelligent exploration of semantic data. The key improvements to what we have previously proposed include the addition of a string similarity measure for the literal neighbors, development of a stability measure to evaluate the accuracy of class relations, the addition of auto-generated property weights, and the detection of noise properties.},
author = {Aydar, Mehmet and Ayvaz, Serkan and Melton, Austin},
file = {:D$\backslash$:/Mendeley/Automatic Weight Generation and Class predicates stability in RDF summary graph.pdf:pdf},
issn = {16130073},
journal = {CEUR Workshop Proceedings},
keywords = {Automatic property weight,Graph summarization,RDF,Semantic web},
title = {{Automatic weight generation and class predicate stability in RDF summary graphs}},
volume = {1472},
year = {2015}
}
@article{Ren2018,
abstract = {The trade-off between language expressiveness and system scalability (E{\&}S) is a well-known problem in RDF stream reasoning. Higher expressiveness supports more complex reasoning logic, however, it may also hinder system scal-ability. Current research mainly focuses on logical frameworks suitable for stream reasoning as well as the implementation and the evaluation of prototype systems. These systems are normally developed in a centralized setting which suffer from inherent limited scalability, while an in-depth study of applying distributed so-lutions to cover E{\&}S is still missing. In this paper, we aim to explore the fea-sibility of applying modern distributed computing frameworks to meet E{\&}S all together. To do so, we first propose BigSR, a technical demonstrator that supports a positive fragment of the LARS framework. For the sake of generality and to cover a wide variety of use cases, BigSR relies on the two main execution models adopted by major distributed execution frameworks: Bulk Synchronous Process-ing (BSP) and Record-at-A-Time (RAT). Accordingly, we implement BigSR on top of Apache Spark Streaming (BSP model) and Apache Flink (RAT model). In order to conclude on the impacts of BSP and RAT on E{\&}S, we analyze the ability of the two models to support distributed stream reasoning and identify several types of use cases characterized by their levels of support. This classi-fication allows for quantifying the E{\&}S trade-off by assessing the scalability of each type of use case w.r.t. its level of expressiveness. Then, we conduct a se-ries of experiments with 15 queries from 4 different datasets. Our experiments show that BigSR over both BSP and RAT generally scales up to high throughput beyond million-triples per second (with or without recursion), and RAT attains sub-millisecond delay for stateless query operators.},
archivePrefix = {arXiv},
arxivId = {arXiv:1804.04367v1},
author = {Ren, Xiangnan and Cur{\'{e}}, Olivier and Naacke, Hubert and Xiao, Guohui},
eprint = {arXiv:1804.04367v1},
file = {:D$\backslash$:/Mendeley/BigSR{\_} An empirical study of real-time expressive RDF.pdf:pdf},
keywords = {Datalog,Distributed System,Semantic Web,Stream Reasoning},
pages = {1--16},
title = {{BigSR: an empirical study of real-time expressive RDF stream reasoning on modern Big Data platforms}},
url = {https://arxiv.org/pdf/1804.04367.pdf},
year = {2018}
}
@article{Fernandez2013,
abstract = {The current Web of Data is producing increasingly large RDF datasets. Massive publication efforts of RDF data driven by initiatives like the Linked Open Data movement, and the need to exchange large datasets has unveiled the drawbacks of traditional RDF representations, inspired and designed by a document-centric and human-readable Web. Among the main problems are high levels of verbosity/redundancy and weak machine-processable capabilities in the description of these datasets. This scenario calls for efficient formats for publication and exchange. This article presents a binary RDF representation addressing these issues. Based on a set of metrics that characterizes the skewed structure of real-world RDF data, we develop a proposal of an RDF representation that modularly partitions and efficiently represents three components of RDF datasets: Header information, a Dictionary, and the actual Triples structure (thus called HDT). Our experimental evaluation shows that datasets in HDT format can be compacted by more than fifteen times as compared to current naive representations, improving both parsing and processing while keeping a consistent publication scheme. Specific compression techniques over HDT further improve these compression rates and prove to outperform existing compression solutions for efficient RDF exchange. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {Fern{\'{a}}ndez, Javier D. and Mart{\'{i}}nez-Prieto, Miguel A. and Guti{\'{e}}rrez, Claudio and Polleres, Axel and Arias, Mario},
doi = {10.1016/j.websem.2013.01.002},
file = {:D$\backslash$:/Mendeley/Binary RDF representation for publication and exchange (HDT).pdf:pdf},
issn = {15708268},
journal = {Journal of Web Semantics},
keywords = {Binary formats,Data compaction and compression,RDF,RDF metrics},
pages = {22--41},
publisher = {Elsevier B.V.},
title = {{Binary RDF representation for publication and exchange (HDT)}},
url = {http://dx.doi.org/10.1016/j.websem.2013.01.002},
volume = {19},
year = {2013}
}
@article{Hadi2013a,
abstract = {The Internet has fundamentally changed the way we collect, access, and deliver information. However, this now means that finding the exact information we need is a significant problem. While search engines can find information based on the keywords we provide, using this technique alone is insufficient for rich information retrieval. Consequently, solutions, which lack the understanding of the syntax and semantics of content, find it difficult to accurately access the information we need. New approaches have been proposed that try to overcome this limitation by utilising Semantic Web and Linked Data techniques. Content is serialised using RDF, and queries executed using SPARQL. This approach requires an exact match between the query structure and the RDF content. While this is an improvement to keyword-based search, there is no support for probabilistic reasoning to show how close a query is to the content being searched. In this paper, we address this limitation by converting RDF content into a matrix of features and treat queries as a classification problem. We have successfully developed a working prototype system to demonstrate the applicability of our approach.},
author = {Hadi, Asaad Sabah and Fergus, Paul and Dobbins, Chelsea and Al-Bakry, Abbas Muhsin},
doi = {10.1109/WAINA.2013.204},
file = {:D$\backslash$:/Mendeley/A Machine Learning Algorithm for Searching vectorised RDF Data.pdf:pdf},
isbn = {9780769549521},
journal = {Proceedings - 27th International Conference on Advanced Information Networking and Applications Workshops, WAINA 2013},
keywords = {Linked Data,Machine Learning,Matrix,RDF,SPARQL,Semantic Web,Vectorisation,and Classification},
pages = {613--618},
title = {{A machine learning algorithm for searching vectorised RDF data}},
year = {2013}
}
@article{Dessi2016,
abstract = {In this paper we address the problem of providing an order of relevance, or ranking, among entities' properties used in RDF datasets, Linked Data and SPARQL endpoints. We first motivate the importance of ranking RDF properties by providing two killer applications for the problem, namely property tagging and entity visualization. Moved by the desiderata of these applications, we propose to apply Machine Learning to Rank (MLR) techniques to the problem of ranking RDF properties. Our devised solution is based on a deep empirical study of all the dimensions involved: feature selection, MLR algorithm and Model training. The major advantages of our approach are the following: (a) flexibility/personalization, as the properties' relevance can be user-specified by personalizing the training set in a supervised approach, or set by a novel automatic classification approach based on SWiPE; (b) speed, since it can be applied without computing frequencies over the whole dataset, leveraging existing fast MLR algorithms; (c) effectiveness, as it can be applied even when no ontology data is available by using novel dataset-independent features; (d) precision, which is high both in terms of f-measure and Spearman's rho. Experimental results show that the proposed MLR framework outperform the two existing approaches found in literature which are related to RDF property ranking.},
author = {Dessi, Andrea and Atzori, Maurizio},
doi = {10.1016/j.future.2015.04.018},
file = {:D$\backslash$:/Mendeley/A machine-learning approach to ranking RDF properties.pdf:pdf},
isbn = {9031220280},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Fast property ranking,Machine learning,Semantic web,User experience},
pages = {366--377},
pmid = {25653388},
publisher = {Elsevier B.V.},
title = {{A machine-learning approach to ranking RDF properties}},
url = {http://dx.doi.org/10.1016/j.future.2015.04.018},
volume = {54},
year = {2016}
}
@article{Moawed2018,
author = {Moawed, Seham and Algergawy, Alsayed and Sarhan, Amany and Eldosouky, Ali},
file = {:D$\backslash$:/Mendeley/A Framework for Efficient Matching of Large-Scale Metadata Models.pdf:pdf},
keywords = {Metadata model matching,Large-scale matching,Parti,hierarchical clustering methods,large-scale matching,metadata model matching,partitioning-based matching},
publisher = {Springer Berlin Heidelberg},
title = {{RESEARCH ARTICLE - COMPUTER ENGINEERING AND COMPUTER SCIENCE A Framework for Efficient Matching of Large-Scale Metadata Models}},
year = {2018}
}
@article{Manolescu2012,
author = {Manolescu, Ioana},
file = {:D$\backslash$:/Mendeley/Query-Oriented Summarization of RDF Graphs.pdf:pdf},
number = {may},
pages = {2012--2015},
title = {{Query-Oriented Summarization of RDF Graphs}},
year = {2012}
}
@article{Hees2016,
abstract = {Efficient usage of the knowledge provided by the Linked Data community is often hindered by the need for domain experts to formulate the right SPARQL queries to answer questions. For new questions they have to decide which datasets are suitable and in which terminology and modelling style to phrase the SPARQL query. In this work we present an evolutionary algorithm to help with this challenging task. Given a training list of source-target node-pair examples our algorithm can learn patterns (SPARQL queries) from a SPARQL endpoint. The learned patterns can be visualised to form the basis for further investigation, or they can be used to predict target nodes for new source nodes. Amongst others, we apply our algorithm to a dataset of several hundred human associations (such as "circle - square") to find patterns for them in DBpedia. We show the scalability of the algorithm by running it against a SPARQL endpoint loaded with {\textgreater} 7.9 billion triples. Further, we use the resulting SPARQL queries to mimic human associations with a Mean Average Precision (MAP) of 39.9 {\%} and a Recall@10 of 63.9 {\%}.},
archivePrefix = {arXiv},
arxivId = {1607.07249},
author = {Hees, J{\"{o}}rn and Bauer, Rouven and Folz, Joachim and Borth, Damian and Dengel, Andreas},
doi = {10.1007/978-3-319-49004-5_22},
eprint = {1607.07249},
file = {:D$\backslash$:/Mendeley/An Evolutionary Algorithm to Learn SPARQL.pdf:pdf},
isbn = {9783319490038},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {337--352},
title = {{An evolutionary algorithm to learn SPARQL queries for source-target-pairs finding patterns for human associations in DBpedia}},
volume = {10024 LNAI},
year = {2016}
}
@phdthesis{Cesar,
author = {Cesar, Gregory and Vilca, Valderrama},
file = {:D$\backslash$:/Mendeley/RESUMENES{\_}ABSTRACTIVOS{\_}ANALISIS{\_}SEMANTICO.pdf:pdf},
pages = {80},
title = {{Generaci{\'{o}}n autom{\'{a}}tica de res{\'{u}}menes abstractivos mono documento utilizando an{\'{a}}lisis sem{\'{a}}ntico y del discurso}},
year = {2017}
}
@article{,
file = {:D$\backslash$:/Mendeley/Semantic Web for the Working Ontologist Effective Modeling in RDFS and OWL.pdf:pdf},
isbn = {9780123735560},
title = {{No Title}}
}
@article{Chai2006,
abstract = {This paper describes a study on automatic music segmentation and summarization from audio signals. The paper inquires scientifically into the nature of human perception of music and offers a practical solution to difficult problems of machine intelligence for automated multimedia content analysis and information retrieval. Specifically, three problems are addressed: segmentation based on tonality analysis, segmentation based on recurrent structural analysis, and summarization. Experimental results are evaluated quantitatively, demonstrating the promise of the proposed methods},
author = {Chai, Wei},
doi = {10.1109/MSP.2006.1598088},
file = {:D$\backslash$:/Mendeley/Semantic Segmentation and summarization of music.pdf:pdf},
isbn = {1053-5888},
issn = {10535888},
journal = {IEEE Signal Processing Magazine},
number = {2},
pages = {124--132},
title = {{Semantic segmentation and summarization of music}},
volume = {23},
year = {2006}
}
@article{Hees2017,
author = {Hees, J{\"{o}}rn and Bauer, Rouven and Folz, Joachim and Borth, Damian and Dengel, Andreas},
file = {:D$\backslash$:/Mendeley/Predicting Human Associations with Graph.pdf:pdf},
issn = {16130073},
journal = {CEUR Workshop Proceedings},
pages = {1--4},
title = {{Predicting human associations with graph patterns learned from linked data}},
volume = {1963},
year = {2017}
}
@article{Barati2017,
abstract = {The Semantic Web opens up new opportunities for the data mining research. Semantic Web data is usually represented in the RDF triple format (subject, predicate, object). Large RDF-style Knowledge Bases contain hundreds of millions of RDF triples that represent knowledge in a machine-understandable format. Association rule mining is one of the most effective techniques for detecting frequent patterns. In the context of Semantic Web data mining, most existing methods rely on users intervention that is time-consuming and error-prone due to a large amount of data. Meanwhile, rule quality factors (e.g. support and confidence) usually consider knowledge at the instance-level. Namely, these factors disregard the knowledge embedded at the schema-level. In this paper, we demonstrate that ignoring knowledge encoded at the schema-level negatively impacts the interpretation of discovered rules. We introduce an approach called SWARM (Semantic Web Association Rule Mining) that automatically mines Semantic Association Rules from RDF data. The main achievement of SWARM is to reveal common behavioural patterns associated with knowledge at the instance-level and schema-level. We discuss how to utilize knowledge encoded at the schema-level to add more semantics to the rules. We compare the semantic of rules discovered by SWRAM with one of the latest approaches in this field to show the importance of considering schema-level knowledge. Initial experiments performed on RDF-style Knowledge Bases demonstrate the effectiveness of the proposed approach.},
author = {Barati, Molood and Bai, Quan and Liu, Qing},
doi = {10.1016/j.knosys.2017.07.009},
file = {:D$\backslash$:/Mendeley/Mining Semantic Association rules from RDF Data.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Association rule mining,Knowledge discovery,Ontology,Semantic Web data},
pages = {183--196},
publisher = {Elsevier B.V.},
title = {{Mining semantic association rules from RDF data}},
url = {http://dx.doi.org/10.1016/j.knosys.2017.07.009},
volume = {133},
year = {2017}
}
@article{Chah2018,
abstract = {This paper reconstructs the Freebase data dumps to understand the underlying ontology behind Google's semantic search feature. The Freebase knowledge base was a major Semantic Web and linked data technology that was acquired by Google in 2010 to support the Google Knowledge Graph, the backend for Google search results that include structured answers to queries instead of a series of links to external resources. After its shutdown in 2016, Freebase is contained in a data dump of 1.9 billion Resource Description Format (RDF) triples. A recomposition of the Freebase ontology will be analyzed in relation to concepts and insights from the literature on classification by Bowker and Star. This paper will explore how the Freebase ontology is shaped by many of the forces that also shape classification systems through a deep dive into the ontology and a small correlational study. These findings will provide a glimpse into the proprietary blackbox Knowledge Graph and what is meant by Google's mission to "organize the world's information and make it universally accessible and useful".},
archivePrefix = {arXiv},
arxivId = {1805.03885},
author = {Chah, Niel},
eprint = {1805.03885},
file = {:D$\backslash$:/Mendeley/OK Google, What Is Your Ontology.pdf:pdf},
keywords = {classification,freebase,google,knowledge graph,ontology},
title = {{OK Google, What Is Your Ontology? Or: Exploring Freebase Classification to Understand Google's Knowledge Graph}},
url = {http://arxiv.org/abs/1805.03885},
year = {2018}
}
@article{Ouksili2018,
abstract = {An increasing number of RDF datasets are available on the Web. In order to query these datasets, users must have some information about their content as well as some knowledge of a query language such as SPARQL. Our goal is to facilitate the exploration of these datasets. In this paper, we introduce two complementary approaches designed to explore RDF(S)/OWL data: theme-based exploration and keyword search. These two approaches rely on the definition of patterns to formalize users' requirements during the exploration process. We present PATEX, a system designed to explore RDF(S)/OWL datasets using the two exploration strategies, allowing the user to interactively switch between them. We also present some experiments on real datasets to illustrate the effectiveness of our approach.},
author = {Ouksili, Hanane and Kedad, Zoubida and Lopes, St{\'{e}}phane and Nugier, Sylvaine},
doi = {10.1016/j.datak.2017.06.003},
file = {:D$\backslash$:/Mendeley/Pattern oriented RDF graphs exploration.pdf:pdf},
isbn = {9783319417530},
issn = {0169023X},
journal = {Data and Knowledge Engineering},
keywords = {Keyword search,Pattern,RDF graph exploration,Theme discovery},
number = {June 2017},
pages = {116--128},
publisher = {Elsevier B.V.},
title = {{Pattern oriented RDF graphs exploration}},
url = {https://doi.org/10.1016/j.datak.2017.06.003},
volume = {113},
year = {2018}
}
@article{Tao2014,
author = {Tao, Cui and Pathak, Jyotishman and Solbrig, Harold R and Wei, Wei-qi and Chute, Christopher G},
file = {:D$\backslash$:/Mendeley/LexRDF{\_}Model{\_}An{\_}RDF-based{\_}Unified{\_}Model{\_}for{\_}Hetero.pdf:pdf},
issn = {1613-0073},
number = {October 2009},
title = {{LexRDF Model : An RDF-based Unified Model for Heterologous Biomedical Ontologies ?}},
year = {2014}
}
@article{Kabir2014,
abstract = {Semantic web offers a smarter web service which synchronizes and arranges all the data over web in a disciplined manner. In data mining over web, the accuracy of selecting necessary data according to user demand and pick them for output is considered as a major challenging task over the years. This paper proposes an approach to mapping data over the web 3.0 through ontology and access the required data via an intelligent agent. The agent provides all the searched data related to user query from which user can find desired information. When the user does not have sufficient search parameter, knowledge can be perceived from the information provided by the agent. The derivation of such unknown knowledge from the existing can be achieved by semantic web mining. We present an intelligent agent-based web mining model where users' query is being searched by following existing traditional way, e.g. by Google. The intelligent agent checks the searched data and derives only those are the semantically related to users search parameter. A work-in-progress case study of University Faculty Information presented to examine the effectiveness of the proposed model.},
author = {Kabir, Sumaiya and Ripon, Shamim and Rahman, Mamunur and Rahman, Tanjim},
doi = {10.1016/j.ieri.2014.08.018},
file = {:D$\backslash$:/Mendeley/Knowledge based Data Mining Using Semantic Web.pdf:pdf},
isbn = {2212-6678},
issn = {22126678},
journal = {IERI Procedia},
pages = {113--119},
publisher = {Elsevier B.V.},
title = {{Knowledge-based Data Mining Using Semantic Web}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212667814000379},
volume = {7},
year = {2014}
}
@article{Leskovec2004,
abstract = {In this paper we present a method for summarizing document by creating a semantic graph of the original document and identifying the substructure of such a graph that can be used to extract sentences for a document summary. We start with deep syntactic analysis of the text and, for each sentence, extract logical form triples, subjectâ€“predicateâ€“object. We then apply cross-sentence pronoun resolution, co-reference resolution, and semantic normalization to refine the set of triples and merge them into a semantic graph. This procedure is applied to both documents and corresponding summary extracts. We train linear Support Vector Machine on the logical form triples to learn how to extract triples that belong to sentences in document summaries. The classifier is then used for automatic creation of document summaries of test data. Our experiments with the DUC 2002 data show that increasing the set of attributes to include semantic properties and topological graph properties of logical triples yields statistically significant improvement of the micro-average F1 measure for the extracted summaries. We also observe that attributes describing various aspects of semantic graph are weighted highly by SVM in the learned model.},
author = {Leskovec, Jure and Grobelnik, Marko and Milic-Frayling, Natasa},
file = {:D$\backslash$:/Mendeley/Learning Sub-structures of Document Semantic Graphs.pdf:pdf},
journal = {LinkKDD Workshop},
keywords = {Information Retrieval {\&} Textual Information Access,Learning/Statistics {\&} Optimisation,Natural Language Processing},
number = {August},
pages = {133--138},
title = {{Learning Sub-structures of Document Semantic Graphs for Document Summarization}},
url = {http://eprints.pascal-network.org/archive/00000847/},
year = {2004}
}
@article{Colucci2017,
abstract = {Comparison of resources is a frequent task in different bio-informatics applications, including drug-target interaction, drug repositioning and mechanism of action understanding, among others. This paper proposes a general method for the logical comparison of resources modeled in Resource Description Framework and shows its distinguishing features with reference to the comparison of drugs. In particular, the method returns a description of the commonalities between resources, rather than a numerical value estimating their similarity and/or relatedness. The approach is domain-independent and may be flexibly adapted to heterogeneous use cases, according to a process for setting parameters which is completely explicit. The paper also presents an experiment using the dataset Bioportal as knowledge source; the experiment is fully reproducible, thanks to the elicitation of criteria and values for parameter customization.},
author = {Colucci, S. and Donini, F. M. and {Di Sciascio}, E.},
doi = {10.1016/j.jbi.2017.11.004},
file = {:D$\backslash$:/Mendeley/Logical comparison over RDF resources in bio-informatics.pdf:pdf},
isbn = {1532-0480 (Electronic)
1532-0464 (Linking)},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Bioportal,Least common subsumer,Logical comparison,RDF,Web of data},
number = {September},
pages = {87--101},
pmid = {29127041},
publisher = {Elsevier},
title = {{Logical comparison over RDF resources in bio-informatics}},
url = {https://doi.org/10.1016/j.jbi.2017.11.004},
volume = {76},
year = {2017}
}
@article{Tekli2018,
abstract = {In the past decade, there has been an increasing need for semantic-aware data search and indexing in textual (structured and NoSQL) databases, as full-text search systems became available to non-experts where users have no knowledge about the data being searched and often formulate query keywords which are different from those used by the authors in indexing relevant documents, thus producing noisy and sometimes irrelevant results. In this paper, we address the problem of semantic-aware querying and provide a general framework for modeling and processing semantic-based keyword queries in textual databases, i.e., considering the lexical and semantic similarities/disparities when matching user query and data index terms. To do so, we design and construct a semantic-aware inverted index structure called SemIndex, extending the standard inverted index by constructing a tightly coupled inverted index graph that combines two main resources: a semantic network and a standard inverted index on a collection of textual data. We then provide a general keyword query model with specially tailored query processing algorithms built on top of SemIndex, in order to produce semantic-aware results, allowing the user to choose the results' semantic coverage and expressiveness based on her needs. To investigate the practicality and effectiveness of SemIndex, we discuss its physical design within a standard commercial RDBMS allowing to create, store, and query its graph structure, thus enabling the system to easily scale up and handle large volumes of data. We have conducted a battery of experiments to test the performance of SemIndex, evaluating its construction time, storage size, query processing time, and result quality, in comparison with legacy inverted index. Results highlight both the effectiveness and scalability of our approach.},
author = {Tekli, Joe and Chbeir, Richard and Traina, Agma J.M. and Traina, Caetano and Yetongnon, Kokou and Ibanez, Carlos Raymundo and {Al Assad}, Marc and Kallas, Christian},
doi = {10.1016/j.datak.2018.07.007},
file = {:D$\backslash$:/Mendeley/Full-fledged semantic indexing and querying model designed for seamless integration in legacy RDBMS.pdf:pdf},
issn = {0169023X},
journal = {Data and Knowledge Engineering},
keywords = {Inverted index,NoSQL indexing,Semantic network,Semantic queries,Semantic-aware data processing,Textual databases},
publisher = {Elsevier B.V.},
title = {{Full-fledged semantic indexing and querying model designed for seamless integration in legacy RDBMS}},
url = {https://doi.org/10.1016/j.datak.2018.07.007},
year = {2018}
}
@article{Moussallem2018,
abstract = {The generation of natural language from Resource Description Framework (RDF) data has recently gained significant attention due to the continuous growth of Linked Data. A number of these approaches generate natural language in languages other than English, however, no work has been proposed to generate Brazilian Portuguese texts out of RDF. We address this research gap by presenting RDF2PT, an approach that verbalizes RDF data to Brazilian Portuguese language. We evaluated RDF2PT in an open questionnaire with 44 native speakers divided into experts and non-experts. Our results suggest that RDF2PT is able to generate text which is similar to that generated by humans and can hence be easily understood.},
archivePrefix = {arXiv},
arxivId = {1802.08150},
author = {Moussallem, Diego and Ferreira, Thiago Castro and Zampieri, Marcos and Cavalcanti, Maria Claudia and Xex{\'{e}}o, Geraldo and Neves, Mariana and Ngomo, Axel-Cyrille Ngonga},
eprint = {1802.08150},
file = {:D$\backslash$:/Mendeley/Generating Brazilian Portuguese Texts from RDF Data.pdf:pdf},
keywords = {natural language generation,semantic web,verbalization},
title = {{RDF2PT: Generating Brazilian Portuguese Texts from RDF Data}},
url = {http://arxiv.org/abs/1802.08150},
year = {2018}
}
@article{Moussallem2018,
abstract = {Efficient usage of the knowledge provided by the Linked Data community is often hindered by the need for domain experts to formulate the right SPARQL queries to answer questions. For new questions they have to decide which datasets are suitable and in which terminology and modelling style to phrase the SPARQL query. In this work we present an evolutionary algorithm to help with this challenging task. Given a training list of source-target node-pair examples our algorithm can learn patterns (SPARQL queries) from a SPARQL endpoint. The learned patterns can be visualised to form the basis for further investigation, or they can be used to predict target nodes for new source nodes. Amongst others, we apply our algorithm to a dataset of several hundred human associations (such as "circle - square") to find patterns for them in DBpedia. We show the scalability of the algorithm by running it against a SPARQL endpoint loaded with {\textgreater} 7.9 billion triples. Further, we use the resulting SPARQL queries to mimic human associations with a Mean Average Precision (MAP) of 39.9 {\%} and a Recall@10 of 63.9 {\%}.},
archivePrefix = {arXiv},
arxivId = {1607.07249},
author = {Ayvaz, Serkan and Aydar, Mehmet and Jiang, Jing and Wang, Chunhui and Tian, Yu and Zhang, Shaoyao and Zhao, Yan and Abacha, Asma Ben and Zweigenbaum, Pierre and Ticona-herrera, Regina and Tekli, Joe and Dongo, Irvin and Guzman, Renato and Chbeir, Richard and Discipline, S T a P S and Cnu, Section and Vincent, Chaubet and Richard, Montoya and Nicolas, Forestier and Hassad, Sara El and {\v{Z}}liobaitÄ—, IndrÄ— and {De Vries}, Gerben Klaas Dirk and {De Rooij}, Steven and Manolescu, Ioana and Hees, J{\"{o}}rn and Bauer, Rouven and Folz, Joachim and Borth, Damian and Dengel, Andreas and Zhu, Ganggao and Iglesias, Carlos A. and Chai, Wei and Cesar, Gregory and Vilca, Valderrama and Manolescu, Ioana and Hees, J{\"{o}}rn and Bauer, Rouven and Folz, Joachim and Borth, Damian and Dengel, Andreas and Ouksili, Hanane and Kedad, Zoubida and Lopes, St{\'{e}}phane and Nugier, Sylvaine and Chah, Niel and Barati, Molood and Bai, Quan and Liu, Qing and Colucci, S. and Donini, F. M. and {Di Sciascio}, E. and Tao, Cui and Pathak, Jyotishman and Solbrig, Harold R and Wei, Wei-qi and Chute, Christopher G and Leskovec, Jure and Grobelnik, Marko and Milic-Frayling, Natasa and Kabir, Sumaiya and Ripon, Shamim and Rahman, Mamunur and Rahman, Tanjim and Kushwaha, Nidhi and Singh, Bharat and Mahule, Rajesh and Vyas, O. P. and Liu, Yike and Safavi, Tara and Dighe, Abhilash and Koutra, Danai and Moussallem, Diego and Ferreira, Thiago Castro and Zampieri, Marcos and Cavalcanti, Maria Claudia and Xex{\'{e}}o, Geraldo and Neves, Mariana and Ngomo, Axel-Cyrille Ngonga and Tekli, Joe and Chbeir, Richard and Traina, Agma J.M. and Traina, Caetano and Yetongnon, Kokou and Ibanez, Carlos Raymundo and {Al Assad}, Marc and Kallas, Christian and Arnaout, Hiba and Elbassuoni, Shady and Xylogiannopoulos, Konstantinos F and Karampelas, Panagiotis and Alhajj, Reda and Ayvaz, Serkan and Aydar, Mehmet and Melton, Austin and Hayes, Jonathan and Gutierrez, Claudio and Fern{\'{a}}ndez, Javier D. and Mart{\'{i}}nez-Prieto, Miguel A. and Guti{\'{e}}rrez, Claudio and Polleres, Axel and Arias, Mario and Ren, Xiangnan and Cur{\'{e}}, Olivier and Naacke, Hubert and Xiao, Guohui and Aydar, Mehmet and Ayvaz, Serkan and Melton, Austin and Potoniec, Jedrzej and Hees, J{\"{o}}rn and Bauer, Rouven and Folz, Joachim and Borth, Damian and Dengel, Andreas and Dessi, Andrea and Atzori, Maurizio and Hadi, Asaad Sabah and Fergus, Paul and Dobbins, Chelsea and Al-Bakry, Abbas Muhsin and {\v{C}}ebiri{\'{c}}, {\v{S}}ejla and Goasdou{\'{e}}, Fran{\c{c}}ois and Manolescu, Ioana and Moawed, Seham and Algergawy, Alsayed and Sarhan, Amany and Eldosouky, Ali and Centers, Data and Majumder, Goutam and Pakray, Partha and Gelbukh, Alexander and Pinto, David and Puebla, De and Allahyari, Mehdi and Trippe, Elizabeth D and Gutierrez, Juan B and Ahmed, Mohiuddin and Allahyari, Mehdi and Trippe, Elizabeth D and Gutierrez, Juan B and Majumder, Goutam and Pakray, Partha and Gelbukh, Alexander and Pinto, David and Puebla, De and Centers, Data and Liu, Yike and Safavi, Tara and Dighe, Abhilash and Koutra, Danai and Llanes, Kathrin Rodriguez and Casanova, Marco Antonio and Lemus, Noel Moreno and Ahmed, Mohiuddin and VanDerHorn, Eric and Mahadevan, Sankaran},
doi = {10.1007/978-3-319-49004-5_22},
eprint = {1607.07249},
file = {:D$\backslash$:/Mendeley/Semantic Segmentation and summarization of music.pdf:pdf;:D$\backslash$:/Mendeley/Translating Medical Questions into SPARQL Queries.pdf:pdf;:D$\backslash$:/Mendeley/Semantic Web for the Working Ontologist Effective Modeling in RDFS and OWL.pdf:pdf;:D$\backslash$:/Mendeley/Semantic Textual Similarity Methods, Tools, and Applications.pdf:pdf;:D$\backslash$:/Mendeley/Sematch Semantic similarity framework for Knowledge Graph.pdf:pdf;:D$\backslash$:/Mendeley/Text Summarization Techniques A Brief Survey.pdf:pdf;:D$\backslash$:/Mendeley/Mining Semantic Association rules from RDF Data.pdf:pdf;:D$\backslash$:/Mendeley/Using RDF Summary Graph For Keyword-based Semantic Searches.pdf:pdf;:D$\backslash$:/Mendeley/Data summarization a survey.pdf:pdf;:D$\backslash$:/Mendeley/Logical comparison over RDF resources in bio-informatics.pdf:pdf;:D$\backslash$:/Mendeley/OK Google, What Is Your Ontology.pdf:pdf;:D$\backslash$:/Mendeley/Pattern oriented RDF graphs exploration.pdf:pdf;:D$\backslash$:/Mendeley/LexRDF{\_}Model{\_}An{\_}RDF-based{\_}Unified{\_}Model{\_}for{\_}Hetero.pdf:pdf;:D$\backslash$:/Mendeley/Predicting Human Associations with Graph.pdf:pdf;:D$\backslash$:/Mendeley/Query-Oriented Summarization of RDF Graphs.pdf:pdf;:D$\backslash$:/Mendeley/RESUMENES{\_}ABSTRACTIVOS{\_}ANALISIS{\_}SEMANTICO.pdf:pdf;:D$\backslash$:/Mendeley/Slides{\_}An Evolutionary Algorithm to Learn SPARQL.pdf:pdf;:D$\backslash$:/Mendeley/Toward RDF Normalization.pdf:pdf;:D$\backslash$:/Mendeley/Urban Activity Summarization with Geo-Tagged Social Media Data.pdf:pdf;:D$\backslash$:/Mendeley/Learning Sub-structures of Document Semantic Graphs.pdf:pdf;:D$\backslash$:/Mendeley/Binary RDF representation for publication and exchange (HDT).pdf:pdf;:D$\backslash$:/Mendeley/A Machine Learning Algorithm for Searching vectorised RDF Data.pdf:pdf;:D$\backslash$:/Mendeley/Knowledge based Data Mining Using Semantic Web.pdf:pdf;:D$\backslash$:/Mendeley/A machine-learning approach to ranking RDF properties.pdf:pdf;:D$\backslash$:/Mendeley/handbook on Data Centers.pdf:pdf;:D$\backslash$:/Mendeley/Automatic Weight Generation and Class predicates stability in RDF summary graph.pdf:pdf;:D$\backslash$:/Mendeley/Summarizing and Understanding Large Graphs.pdf:pdf;:D$\backslash$:/Mendeley/Building Summary Graphs of RDF Data in Semantic web.pdf:pdf;:D$\backslash$:/Mendeley/From Sensor Data Streams to Linked Streaming Data.pdf:pdf;:D$\backslash$:/Mendeley/An On-Line Learning to Query System.pdf:pdf;:D$\backslash$:/Mendeley/Validating RDF Data.pdf:pdf;:D$\backslash$:/Mendeley/Bayesian model updating with summarized statistical and reliability data.pdf:pdf;:D$\backslash$:/Mendeley/Graph Summarization Methods and Aplications{\_}A Survey.pdf:pdf;:D$\backslash$:/Mendeley/BigSR{\_} An empirical study of real-time expressive RDF.pdf:pdf;:D$\backslash$:/Mendeley/handbook on Data Centers(2).pdf:pdf;:D$\backslash$:/Mendeley/A Framework for Efficient Matching of Large-Scale Metadata Models.pdf:pdf;:D$\backslash$:/Mendeley/A Framework for Efficient Representative summarization of RDF Graphs.pdf:pdf;:D$\backslash$:/Mendeley/An Evolutionary Algorithm to Learn SPARQL.pdf:pdf;:D$\backslash$:/Mendeley/Bipartite graphs as intermediate model for RDF.pdf:pdf;:D$\backslash$:/Mendeley/Dynamic Pattern Detection for Big Data stream analytics.pdf:pdf;:D$\backslash$:/Mendeley/Effective searching of RDF knowledge graphs.pdf:pdf;:D$\backslash$:/Mendeley/Full-fledged semantic indexing and querying model designed for seamless integration in legacy RDBMS.pdf:pdf;:D$\backslash$:/Mendeley/Generating Brazilian Portuguese Texts from RDF Data.pdf:pdf;:D$\backslash$:/Mendeley/Graph Summarization Methods and Aplications{\_}A Survey(2).pdf:pdf;:D$\backslash$:/Mendeley/Keyword Prediction with ARM on Bibliographic RDF Data.pdf:pdf;:D$\backslash$:/Mendeley/structural Summatization of Semantic Graphs.pdf:pdf;:D$\backslash$:/Mendeley/Substructure counting graph kernels for machine learning from RDF.pdf:pdf;:D$\backslash$:/Mendeley/THESES Learning Commonalities in RDF and SPARQL.pdf:pdf;:D$\backslash$:/Mendeley/THESES Towards RDF Normalization.pdf:pdf;:D$\backslash$:/Mendeley/Ayvaz et al. - 2018 - An evolutionary algorithm to learn SPARQL queries for source-target-pairs finding patterns for human associations.pdf:pdf},
isbn = {9783319490038},
issn = {16130073},
journal = {CEUR Workshop Proceedings},
keywords = {-data mining,Association rule mining,Assoication rule mining,Automatic property weight,Bayesian network,Binary formats,Bioportal,Calibration,Classification,Cyber security,Data compaction and compression,Data mining,Datalog,Distributed System,Diversity,Evaluation,Fast property ranking,Graph Summarization,Graph kernels,Graph summarization,Hierarchical clustering methods,Hub removal,Information Retrieval {\&} Textual Information Access,Inverted index,Keyword search,Knowledge Graphs,Knowledge discovery,Large-scale matching,Learning/Statistics {\&} Optimisation,Least common subsumer,Linked Data,Linked open data cloud,Logical comparison,Machine Learning,Machine learning,Machine learning for RDF,Matrix,Metadata model matching,Natural Language Processing,Natural language processing,NoSQL indexing,Ontology,Partitioning-based matching,Pattern,Query-answering system,RDF,RDF graph exploration,RDF metrics,Ranking,Relaxation,Reliability,SPARQL,Semantic Web,Semantic Web data,Semantic network,Semantic queries,Semantic similarity,Semantic web,Semantic-aware data processing,Semantics,Statistics,Stream Reasoning,Structured data,Sufficient statistics,Summarization,Summary statistics,Taxonomy,Textual databases,Theme discovery,Unstructured data,User experience,Vectorisation,Web of data,Weisfeiler-Lehman,acm reference format,and Classification,arpad,big data,bipartite graph,cessing,character-based similarity,classification,cosine similarity,data stream,data streams,eliza-,form and widely used,freebase,geo-,google,graph summaries,graph summarization,graph visualization,gtsm,hierarchical clustering methods,ical redundancies,in daily,information content,information extraction,kernel density estimation,knowledge bases,knowledge graph,large-scale matching,least general generalization,lerp-rsa,linked data,log-,machine learning,media,medical question analysis,mehdi allahyari,mehdi assefi,metadata model matching,minimum description length,n-gram,natural language generation,natural language pro-,normalization process,ontology,partitioning-based matching,pattern detection,physical disparities,queries are easier to,question answering,quotient graphs,random walk,rdf,rdf databases,rdf entailment,rdf graph,rdf model,rdf serialization,rdfs,saeid safaei,semantic textual similarity,semantic web,sensor data publishing,seyedamin pouriyeh,social,spatiotemporal hot spot,statistical similarity,tagged social media,term-based similarity,text summarization,topic models,urban activity summarization,verbalization,wordnet taxonomy},
number = {2},
pages = {1--25},
pmid = {25653388},
publisher = {Elsevier B.V.},
title = {{An evolutionary algorithm to learn SPARQL queries for source-target-pairs finding patterns for human associations in DBpedia}},
url = {https://doi.org/10.1016/j.ress.2017.11.023 https://doi.org/10.1007/s10115-018-1183-0 http://www-di.inf.puc-rio.br/{~}casanova//Publications/Papers/2017-Papers/2017-JIDM-1618-10584-1-PB.pdf http://arxiv.org/abs/1612.04883 http://dx.doi.org/10.1016/j.future.2},
volume = {1963},
year = {2018}
}
@article{Liu2016a,
abstract = {While advances in computing resources have made processing enormous amounts of data possible, human ability to identify patterns in such data has not scaled accordingly. Efficient computational methods for condensing and simplifying data are thus becoming vital for extracting actionable insights. In particular, while data summarization techniques have been studied extensively, only recently has summarizing interconnected data, or graphs, become popular. This survey is a structured, comprehensive overview of the state-of-the-art methods for summarizing graph data. We first broach the motivation behind, and the challenges of, graph summarization. We then categorize summarization approaches by the type of graphs taken as input and further organize each category by core methodology. Finally, we discuss applications of summarization on real-world graphs and conclude by describing some open problems in the field.},
archivePrefix = {arXiv},
arxivId = {1612.04883},
author = {Liu, Yike and Safavi, Tara and Dighe, Abhilash and Koutra, Danai},
doi = {10.1145/3186727},
eprint = {1612.04883},
file = {:D$\backslash$:/Mendeley/Graph Summarization Methods and Aplications{\_}A Survey(2).pdf:pdf},
issn = {03600300},
title = {{Graph Summarization Methods and Applications: A Survey}},
url = {http://arxiv.org/abs/1612.04883},
year = {2016}
}
@article{Jiang2018,
author = {Jiang, Jing and Wang, Chunhui and Tian, Yu and Zhang, Shaoyao and Zhao, Yan},
file = {:D$\backslash$:/Mendeley/Urban Activity Summarization with Geo-Tagged Social Media Data.pdf:pdf},
isbn = {9781538669952},
journal = {2018 4th International Conference on Computer and Technology Applications (ICCTA)},
keywords = {-data mining,geo-,gtsm,kernel density estimation,media,social,spatiotemporal hot spot,tagged social media,urban activity summarization},
pages = {16--19},
publisher = {IEEE},
title = {{Urban Activity Summarization with Geo-Tagged Social Media Data}},
year = {2018}
}
@article{Kushwaha2015,
abstract = {Web-3.0 provides an easy way to utilize the in-depth knowledge of the huge data that grows day-by-day in the internet Our aim with this paper is to work with the Linked Open Data Cloud data, where the main problem with the dataset is inconsistencies, bulkiness. We are exploring bibliographic data which is one of the cloud data. The authors found some useful information in the dataset that should be explored for judging the improvement of the search query's result. After analysis we came to know that many of the papers residing in RKBExplorer did not have keyword information. Because of that the search engine based on the RKBExplorer only able to use the information in this database going to retrieve the papers, authors of that paper and their related cited papers with given paper author or title. But assume the situation where the user wants to enter the search string, then what would be the result? Would it retrieve all the related paper even if their keywords are not assigned? In this paper we are trying to answer this question, with the help of data mining algorithm ARM on the features retrieved from the RDF data. We have developed a novel approach through which we can answer the user's query which is mixture of important the strings, we called them tags of the papers.},
author = {Kushwaha, Nidhi and Singh, Bharat and Mahule, Rajesh and Vyas, O. P.},
doi = {10.1016/j.procs.2015.04.019},
file = {:D$\backslash$:/Mendeley/Keyword Prediction with ARM on Bibliographic RDF Data.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Assoication rule mining,Data mining,Linked open data cloud,Query-answering system,RDF},
pages = {490--495},
publisher = {Elsevier Masson SAS},
title = {{Keyword prediction with ARM on bibliographic RDF data}},
url = {http://dx.doi.org/10.1016/j.procs.2015.04.019},
volume = {50},
year = {2015}
}
@article{Abacha2012a,
abstract = {Designing question answering systems requires efficient and deep analysis of natural language questions. A key process for this task is to translate the semantic relations expressed in the question into a machine-readable representation. In this paper we tackle question analysis in the medical field. More precisely, we study how to translate a natural language question into a machine-readable representation. The underlying transformation process requires determining three key points: (i) What are the main characteristics of medical questions? (ii) Which methods are the most fitted for the extraction of these characteristics? and (iii) how to translate the extracted information into a machine-understandable representation? We present a complete question analysis approach including medical entity recognition, semantic relation extraction and automatic translation to SPARQL queries. Our study supports the fact that SPARQL can represent a wide range of natural language questions in a question-answering perspective. Experiments on a corpus of real questions show that we obtain encouraging results in medical entity recognition and relation extraction. The obtained results also show that the output SPARQL queries correctly represent more than 60{\%} of the original questions.},
author = {Abacha, Asma Ben and Zweigenbaum, Pierre},
doi = {10.1145/2110363.2110372},
file = {:D$\backslash$:/Mendeley/Translating Medical Questions into SPARQL Queries.pdf:pdf},
isbn = {9781450307819},
journal = {Proceedings of the 2nd ACM SIGHIT symposium on International health informatics},
keywords = {RDF,SPARQL,information extraction,machine learning,medical question analysis,question answering},
pages = {41--50},
title = {{Medical Question Answering : Translating Medical Questions into SPARQL Queries}},
url = {http://dl.acm.org/citation.cfm?id=2110372{\&}CFID=66417314{\&}CFTOKEN=54431950},
year = {2012}
}
@article{Centers,
author = {Centers, Data},
file = {:D$\backslash$:/Mendeley/handbook on Data Centers(2).pdf:pdf},
isbn = {9781493920914},
title = {{No Title}}
}
@article{Majumder2016,
author = {Majumder, Goutam and Pakray, Partha and Gelbukh, Alexander and Pinto, David and Puebla, De},
doi = {10.13053/CyS-20-4-2506},
file = {:D$\backslash$:/Mendeley/Semantic Textual Similarity Methods, Tools, and Applications.pdf:pdf},
keywords = {cessing,character-based similarity,cosine similarity,information content,n-gram,natural language pro-,random walk,semantic textual similarity,statistical similarity,term-based similarity,wordnet taxonomy},
number = {4},
pages = {647--665},
title = {{Semantic Textual Similarity Methods , Tools , and Applications :}},
volume = {20},
year = {2016}
}
@article{Allahyari,
archivePrefix = {arXiv},
arxivId = {arXiv:1707.02268v3},
author = {Allahyari, Mehdi and Trippe, Elizabeth D and Gutierrez, Juan B},
eprint = {arXiv:1707.02268v3},
file = {:D$\backslash$:/Mendeley/Text Summarization Techniques A Brief Survey.pdf:pdf},
keywords = {acm reference format,eliza-,knowledge bases,mehdi allahyari,mehdi assefi,saeid safaei,seyedamin pouriyeh,text summarization,topic models},
number = {1},
title = {{Text Summarization Techniques : A Brief Survey}}
}
@article{Liu2016,
abstract = {While advances in computing resources have made processing enormous amounts of data possible, human ability to identify patterns in such data has not scaled accordingly. Efficient computational methods for condensing and simplifying data are thus becoming vital for extracting actionable insights. In particular, while data summarization techniques have been studied extensively, only recently has summarizing interconnected data, or graphs, become popular. This survey is a structured, comprehensive overview of the state-of-the-art methods for summarizing graph data. We first broach the motivation behind, and the challenges of, graph summarization. We then categorize summarization approaches by the type of graphs taken as input and further organize each category by core methodology. Finally, we discuss applications of summarization on real-world graphs and conclude by describing some open problems in the field.},
archivePrefix = {arXiv},
arxivId = {1612.04883},
author = {Liu, Yike and Safavi, Tara and Dighe, Abhilash and Koutra, Danai},
eprint = {1612.04883},
file = {:D$\backslash$:/Mendeley/Graph Summarization Methods and Aplications{\_}A Survey.pdf:pdf},
title = {{Graph Summarization Methods and Applications: A Survey}},
url = {http://arxiv.org/abs/1612.04883},
year = {2016}
}
@article{Ahmed2018,
author = {Ahmed, Mohiuddin},
doi = {10.1007/s10115-018-1183-0},
file = {:D$\backslash$:/Mendeley/Data summarization a survey.pdf:pdf},
issn = {02193116},
journal = {Knowledge and Information Systems},
keywords = {Cyber security,Machine learning,Natural language processing,Semantics,Statistics,Structured data,Summarization,Unstructured data},
pages = {1--25},
publisher = {Springer London},
title = {{Data summarization: a survey}},
url = {https://doi.org/10.1007/s10115-018-1183-0},
year = {2018}
}
@article{Allahyari2016,
abstract = {Today, large amounts of data are produced by sensor networks. They are continuously producing data streams about real world phenomena. However, these data streams are generated in raw and different formats, lacking the semantics to describe their meanings, which imposes barriers to accessing and using them. To tackle this problem, several solutions using Linked Data Principles have been proposed. In this article, we survey the main solutions developed by the research communities for publishing data streams in the Web of Data. The major contributions of the article are the identification of the strengths and limitations of these solutions and, over that basis, the main steps that someone should follow to publish data streams in a manner that anyone can use them, with a minimal understanding of the details. We also highlight the main challenges that emerge from this survey, concluding with a list of research tasks for future work.},
archivePrefix = {arXiv},
arxivId = {1612.04883},
author = {Allahyari, Mehdi and Trippe, Elizabeth D and Gutierrez, Juan B and Majumder, Goutam and Pakray, Partha and Gelbukh, Alexander and Pinto, David and Puebla, De and Centers, Data and Liu, Yike and Safavi, Tara and Dighe, Abhilash and Koutra, Danai and Llanes, Kathrin Rodriguez and Casanova, Marco Antonio and Lemus, Noel Moreno and Ahmed, Mohiuddin},
doi = {10.1007/s10115-018-1183-0},
eprint = {1612.04883},
file = {:D$\backslash$:/Mendeley/handbook on Data Centers.pdf:pdf;:D$\backslash$:/Mendeley/Semantic Textual Similarity Methods, Tools, and Applications.pdf:pdf;:D$\backslash$:/Mendeley/From Sensor Data Streams to Linked Streaming Data.pdf:pdf;:D$\backslash$:/Mendeley/Text Summarization Techniques A Brief Survey.pdf:pdf;:D$\backslash$:/Mendeley/Graph Summarization Methods and Aplications{\_}A Survey.pdf:pdf;:D$\backslash$:/Mendeley/Data summarization a survey.pdf:pdf},
isbn = {9781493920914},
issn = {02193116},
journal = {Journal of Information and Data Management},
keywords = {Cyber security,Machine learning,Natural language processing,Semantics,Statistics,Structured data,Summarization,Unstructured data,acm reference format,cessing,character-based similarity,cosine similarity,data streams,eliza-,information content,knowledge bases,linked data,mehdi allahyari,mehdi assefi,n-gram,natural language pro-,random walk,saeid safaei,semantic textual similarity,semantic web,sensor data publishing,seyedamin pouriyeh,statistical similarity,term-based similarity,text summarization,topic models,wordnet taxonomy},
number = {2},
pages = {1--25},
publisher = {Springer London},
title = {{From Sensor Data Streams to Linked Streaming Data: a survey of main approaches}},
url = {https://doi.org/10.1007/s10115-018-1183-0 http://www-di.inf.puc-rio.br/{~}casanova//Publications/Papers/2017-Papers/2017-JIDM-1618-10584-1-PB.pdf http://arxiv.org/abs/1612.04883},
volume = {7},
year = {2016}
}
@article{VanDerHorn2018,
abstract = {The accuracy of model-based reliability analysis is affected by the uncertainty regarding the model parameters used to predict the behavior of the engineering system. The uncertainty in the model parameters can be reduced by combining prior knowledge about the parameters with observed data regarding system inputs and outputs. In some cases, the information about the observations is only available as abstracted data, where the original raw data have been reduced to a summarized representation. Common forms of abstracted data include summary statistics, such as the mean and variance for continuous variables and observed frequencies for discrete variables. In the context of reliability analysis, a common form of available information is summarized reliability data for various mechanical components (e.g., failure rates or failure probabilities) instead of detailed actual test data. This paper presents a methodology for updating the model parameters using these abstracted data forms through a Bayesian network. First, the concept of a statistics function is developed and linked to the abstracted data forms. The concept of arc reversal is then exploited to transform the Bayesian network to a form that can be used to incorporate the statistics function and thereby enable the updating of the model parameters. Several numerical examples are used to demonstrate the applicability and generality of the proposed method for several different forms of abstracted data.},
author = {VanDerHorn, Eric and Mahadevan, Sankaran},
doi = {10.1016/j.ress.2017.11.023},
file = {:D$\backslash$:/Mendeley/Bayesian model updating with summarized statistical and reliability data.pdf:pdf},
issn = {09518320},
journal = {Reliability Engineering and System Safety},
keywords = {Bayesian network,Calibration,Reliability,Sufficient statistics,Summary statistics},
number = {December 2017},
pages = {12--24},
publisher = {Elsevier Ltd},
title = {{Bayesian model updating with summarized statistical and reliability data}},
url = {https://doi.org/10.1016/j.ress.2017.11.023},
volume = {172},
year = {2018}
}
@article{Pagola2009,
abstract = {Measuring the nitrogen nutrition status of plants is useful for nitrogen fertiliser management. As nitrogen is one of the main structural components of chlorophyll, its nutrition status is highly correlated with the greenness of leaves. This paper proposes and evaluates a new low-cost method to estimate the N-nutrition status of plants using digital colour image analysis. A method has been developed in which principal component analysis is applied to digital images to calculate a greenness index using RGB components of the colour image, which yields an estimate of the amount of N in the plant. To evaluate its quality, we calculated the correlation between the index and measurements obtained with a SPAD-502 chlorophyll meter, normally used in decision-making in fertiliser management. The performance of the proposed index is better than that of others previously investigated. Furthermore, the capacity of our index to predict N deficiencies affecting barley yield was equal to or better than that of SPAD measurements under our experimental conditions. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Pagola, Miguel and Ortiz, Rub{\'{e}}n and Irigoyen, Ignacio and Bustince, Humberto and Barrenechea, Edurne and Aparicio-Tejo, Pedro and Lamsfus, Carmen and Lasa, Berta},
doi = {10.1016/j.compag.2008.10.003},
file = {:D$\backslash$:/Mendeley/New method to assess barley nitrogen nutrition status.pdf:pdf},
isbn = {0168-1699},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {Artificial vision application,Barley,Colour image analysis,N-nutrition,Principal component analysis,SPAD},
number = {2},
pages = {213--218},
title = {{New method to assess barley nitrogen nutrition status based on image colour analysis. Comparison with SPAD-502}},
volume = {65},
year = {2009}
}
@article{Yao2009,
abstract = {For detecting rice disease early and accurately, we presented an application of image processing techniques and Support Vector Machine (SVM) for detecting rice diseases. Rice disease spots were segmented and their shape and texture features were extracted. The SVM method was employed to classify rice bacterial leaf blight, rice sheath blight and rice blast. The results showed that SVM could effectively detect and classify these disease spots to an accuracy of 97.2{\%}.},
author = {Yao, Qing and Guan, Zexin and Zhou, Yingfeng and Tang, Jian and Hu, Yang and Yang, Baojun},
doi = {10.1109/ICEC.2009.73},
file = {:D$\backslash$:/Mendeley/Application of support vector machine for detecting rice diseases using shape and.pdf:pdf},
isbn = {978-0-7695-3655-2},
journal = {2009 International Conference on Engineering Computation},
keywords = {-rice diseases spots,baojun yang,china national rice research,features,image processing,institute,jian tang,support vector machine,texture,yang hu},
pages = {79--83},
title = {{Application of Support Vector Machine for Detecting Rice Diseases Using Shape and Color Texture Features}},
url = {http://ieeexplore.ieee.org/document/5167096/},
year = {2009}
}
@article{Article2014,
author = {Article, Review},
file = {:D$\backslash$:/Mendeley/Review Paper on Identification of Plant.pdf:pdf},
keywords = {computer vision,feature extraction,vegetable detection},
number = {6},
pages = {4260--4262},
title = {{Review Paper on Vegetable Identification and Detection using Image Processing}},
volume = {4},
year = {2014}
}
@article{Barbedo2014,
abstract = {A method is presented to detect and quantify leaf symptoms using conventional color digital images. The method was designed to be completely automatic, eliminating the possibility of human error and reducing time taken to measure disease severity. The program is capable of dealing with images containing multiple leaves, further reducing the time taken. Accurate results are possible when the symptoms and leaf veins have similar color and shade characteristics. The algorithm is subject to one constraint: the background must be as close to white or black as possible. Tests showed that the method provided accurate estimates over a wide variety of conditions, being robust to variation in size, shape, and color of leaves; symptoms; and leaf veins. Low rates of false positives and false negatives occurred due to extrinsic factors such as issues with image capture and the use of extreme file compression ratios.},
author = {Barbedo, Jayme Garcia Arnal},
doi = {10.1094/PDIS-03-14-0290-RE},
file = {:D$\backslash$:/Mendeley/barbedo2014.pdf:pdf},
issn = {0191-2917},
journal = {Plant Disease},
number = {12},
pages = {1709--1716},
title = {{An Automatic Method to Detect and Measure Leaf Disease Symptoms Using Digital Image Processing}},
url = {http://apsjournals.apsnet.org/doi/10.1094/PDIS-03-14-0290-RE},
volume = {98},
year = {2014}
}
@article{Larese2014,
abstract = {In this paper, a procedure for segmenting and classifying scanned legume leaves based only on the analysis of their veins is proposed (leaf shape, size, texture and color are discarded). Three legume species are studied, namely soybean, red and white beans. The leaf images are acquired using a standard scanner. The segmentation is performed using the unconstrained hit-or-miss transform and adaptive thresholding. Several morphological features are computed on the segmented venation, and classified using four alternative classifiers, namely support vector machines (linear and Gaussian kernels), penalized discriminant analysis and random forests. The performance is compared to the one obtained with cleared leaves images, which require a more expensive, time consuming and delicate procedure of acquisition. The results are encouraging, showing that the proposed approach is an effective and more economic alternative solution which outperforms the manual expert's recognition. {\textcopyright} 2013 Elsevier Ltd. All rights reserved.},
author = {Larese, M{\'{o}}nica G. and Nam{\'{i}}as, Rafael and Craviotto, Roque M. and Arango, Miriam R. and Gallo, Carina and Granitto, Pablo M.},
doi = {10.1016/j.patcog.2013.06.012},
file = {:D$\backslash$:/Mendeley/Automatic classification of legumes using leaf vein image features.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Leaf vein analysis,Leaf vein features,Leaf vein images,Legume classification,Unconstrained hit-or-miss transform},
number = {1},
pages = {158--168},
publisher = {Elsevier},
title = {{Automatic classification of legumes using leaf vein image features}},
url = {http://dx.doi.org/10.1016/j.patcog.2013.06.012},
volume = {47},
year = {2014}
}
@article{Story2010,
abstract = {Conventional greenhouse environmental conditions are determined by observation. However, destructive or invasive contact measurements are not practical for real-time monitoring and control applications. At the canopy scale, machine vision has the potential to identify emerging stresses and guide sampling for identification of the stressor. A machine vision-guided plant sensing and monitoring system was used to detect calcium deficiency in lettuce crops grown in greenhouse conditions using temporal, color and morphological changes of the plant. The machine vision system consisted of two main components: a robotic camera positioning system and an image processing module. The machine vision system extracted plant features to determine overall plant growth and health status, including top projected canopy area (TPCA) as a morphological feature; red-green-blue (RGB) and hue-saturation-luminance (HSL) values as color features; and entropy, energy, contrast, and homogeneity as textural features. The machine vision-guided system was capable of extracting plant morphological, textural and temporal features autonomously. The methodology developed was capable of identifying calcium-deficient lettuce plants 1 day prior to visual stress detection by human vision. Of the extracted plant features, TPCA, energy, entropy, and homogeneity were the most promising markers for timely detection of calcium deficiency in the lettuce crop studied. {\textcopyright} 2010.},
author = {Story, David and Kacira, Murat and Kubota, Chieri and Akoglu, Ali and An, Lingling},
doi = {10.1016/j.compag.2010.08.010},
file = {:D$\backslash$:/Mendeley/Lettuce calcium deficiency detection with machine vision computed plant.pdf:pdf},
isbn = {0168-1699},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {Image processing,Lettuce,Machine vision,Nutrient deficiency,Real-time crop monitoring},
number = {2},
pages = {238--243},
publisher = {Elsevier B.V.},
title = {{Lettuce calcium deficiency detection with machine vision computed plant features in controlled environments}},
url = {http://dx.doi.org/10.1016/j.compag.2010.08.010},
volume = {74},
year = {2010}
}
@article{Xu2011,
abstract = {Soilless culture has been popular in modern agriculture. However, plants in soilless culture often appear to be nutrient deficient. Therefore the intellective diagnostic system of plants disease of nutrients deficiency is important. In this paper, a novel idea based on computer vision is presented. Color and texture features of leaves are extracted by some methods such as percent intensity histogram, percent differential histogram, Fourier transform, and wavelet packet. Moreover, Genetic Algorithm (GA) has been used to select features to get the best information for diagnosing the disease. Experiments showed that the accuracy of this diagnostic system is above 82.5{\%} and it can diagnose disease about 6-10 days before experts could determine. ?? 2011 Elsevier B.V. All rights reserved.},
author = {Xu, Guili and Zhang, Fengling and Shah, Syed Ghafoor and Ye, Yongqiang and Mao, Hanping},
doi = {10.1016/j.patrec.2011.04.020},
file = {:D$\backslash$:/Mendeley/Use of leaf color images to identify nitrogen and potassium deficient tomatoes.pdf:pdf},
isbn = {0167-8655},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Classification,Computer vision,Feature extraction,Feature selection,Intellective diagnosis},
number = {11},
pages = {1584--1590},
publisher = {Elsevier B.V.},
title = {{Use of leaf color images to identify nitrogen and potassium deficient tomatoes}},
url = {http://dx.doi.org/10.1016/j.patrec.2011.04.020},
volume = {32},
year = {2011}
}
@article{Wang2012,
abstract = {Digital image recognition of plant diseases could reduce the dependence of agricultural production on the professional and technical personnel in plant protection field and is conducive to the development of plant protection informatization. In order to find out a method to realize image recognition of plant diseases, four kinds of neural networks including backpropagation (BP) networks, radial basis function (RBF) neural networks, generalized regression networks (GRNNs) and probabilistic neural networks (PNNs) were used to distinguish wheat stripe rust from wheat leaf rust and to distinguish grape downy mildew from grape powdery mildew based on color features, shape features and texture features extracted from the disease images. The results showed that identification and diagnosis of the plant diseases could be effectively achieved using BP networks, RBF neural networks, GRNNs and PNNs based on image processing. For the two kinds of wheat diseases, the best prediction accuracy was 100{\%} with the fitting accuracy equal to 100{\%} while BP networks, GRNNs or PNNs were used, and the best prediction accuracy was 97.50{\%} with the fitting accuracy equal to 100{\%} while RBF neural networks were used. For the two kinds of grape diseases, the best prediction accuracy was 100{\%} with the fitting accuracy equal to 100{\%} while BP networks, GRNNs or PNNs were used, and the best prediction accuracy was 94.29{\%} with the fitting accuracy equal to 100{\%} while RBF neural networks were used. {\textcopyright} 2012 IEEE.},
author = {Wang, H and Li, G and Ma, Z and Li, X},
doi = {10.1109/ICSAI.2012.6223479},
file = {:D$\backslash$:/Mendeley/Application of Neural Networks to Image.pdf:pdf},
isbn = {9781467301992},
journal = {2012 International Conference on Systems and Informatics, ICSAI 2012},
keywords = {Agricultural productions; Backpropagation network;,Agriculture; Backpropagation; Diagnosis; Forecast,Neural networks},
number = {Icsai},
pages = {2159--2164},
title = {{Application of neural networks to image recognition of plant diseases}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84864227170{\&}partnerID=40{\&}md5=ac0f9c28cab7eaca68ed3aa90c414c1e},
year = {2012}
}
@article{Gal,
abstract = {Deep learning tools have gained tremendous at-tention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In compari-son, Bayesian models offer a mathematically grounded framework to reason about model un-certainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout train-ing in deep neural networks (NNs) as approxi-mate Bayesian inference in deep Gaussian pro-cesses. A direct result of this theory gives us tools to model uncertainty with dropout NNs â€“ extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an ex-tensive study of the properties of dropout's un-certainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predic-tive log-likelihood and RMSE compared to ex-isting state-of-the-art methods, and finish by us-ing dropout's uncertainty in deep reinforcement learning.},
author = {Gal, Yarin and Ghahramani, Zoubin},
file = {:D$\backslash$:/Mendeley/Gal, Ghahramani - Unknown - Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning.pdf:pdf},
title = {{Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning}}
}
@article{Deng2014,
abstract = {Deep Learning: Methods and Applications},
author = {Deng, Li and Yu, Dong},
doi = {10.1561/2000000039},
file = {:D$\backslash$:/Mendeley/Deng, Yu - 2014 - Deep Learning Methods and Applications.pdf:pdf},
issn = {1932-8346},
journal = {Foundations and Trends{\textregistered} in Signal Processing},
keywords = {Architectures for IR,Audio signal processing,Information Retrieval,Signal Processing,Speech and spoken language processing,Statistical/machine learning},
number = {3-4},
pages = {197--387},
publisher = {Now Publishers, Inc.},
title = {{Deep Learning: Methods and Applications}},
url = {http://nowpublishers.com/articles/foundations-and-trends-in-signal-processing/SIG-039},
volume = {7},
year = {2014}
}
@article{Gaszczak2011,
abstract = {A generic and robust approach for the real-time detection of people and vehicles$\backslash$nfrom an Unmanned Aerial Vehicle(UAV) is an important goal within the framework$\backslash$nof fully autonomous UAV deployment for aerial reconnaissance andsurveillance.$\backslash$nHere we present an approach for the automatic detection of vehicles based on$\backslash$nusing multiple trainedcascaded Haar classifiers with secondary confirmation in$\backslash$nthermal imagery. Additionally we present a related approachfor people detection$\backslash$nin thermal imagery based on a similar cascaded classification technique$\backslash$ncombining additionalmultivariate Gaussian shape matching. The results presented$\backslash$nshow the successful detection of vehicle and people undervarying conditions in$\backslash$nboth isolated rural and cluttered urban environments with minimal false positive$\backslash$ndetection.Performance of the detector is optimized to reduce the overall false$\backslash$npositive rate by aiming at the detection of each objectof interest (vehicle/$\backslash$nperson) at least once in the environment (i.e. per search patter flight path)$\backslash$nrather than every object ineach image frame. Currently the detection rate for$\backslash$npeople is {\~{}}70{\%} and cars {\~{}}80{\%} although the overall episodic objectdetection rate$\backslash$nfor each flight pattern exceeds 90{\%}.},
author = {Gaszczak, Anna and Breckon, Toby P. and Han, Jiwan},
doi = {10.1117/12.876663},
file = {:D$\backslash$:/Mendeley/Gaszczak, Breckon, Han - 2011 - Real-time people and vehicle detection from UAV imagery.pdf:pdf},
isbn = {9780819484154},
issn = {0277786X},
journal = {IS{\&}T/SPIE Electronic Imaging},
keywords = {UAV image analysis, people detection, aerial image,aerial image,people detection},
number = {86860B},
pages = {1--13, San Francisco, CA, USA, Jan 2011},
title = {{Real-time people and vehicle detection from UAV imagery}},
url = {http://dx.doi.org/10.1117/12.876663},
year = {2011}
}
@article{Doel2017,
abstract = {Objectives Clinical imaging data are essential for developing research software for computer-aided diagnosis, treatment planning and image-guided surgery, yet existing systems are poorly suited for data sharing between healthcare and academia: research systems rarely provide an integrated approach for data exchange with clinicians; hospital systems are focused towards clinical patient care with limited access for external researchers; and safe haven environments are not well suited to algorithm development. We have established GIFT-Cloud, a data and medical image sharing platform, to meet the needs of GIFT-Surg, an international research collaboration that is developing novel imaging methods for fetal surgery. GIFT-Cloud also has general applicability to other areas of imaging research. Methods GIFT-Cloud builds upon well-established cross-platform technologies. The Server provides secure anonymised data storage, direct web-based data access and a REST API for integrating external software. The Uploader provides automated on-site anonymisation, encryption and data upload. Gateways provide a seamless process for uploading medical data from clinical systems to the research server. Results GIFT-Cloud has been implemented in a multi-centre study for fetal medicine research. We present a case study of placental segmentation for pre-operative surgical planning, showing how GIFT-Cloud underpins the research and integrates with the clinical workflow. Conclusions GIFT-Cloud simplifies the transfer of imaging data from clinical to research institutions, facilitating the development and validation of medical research software and the sharing of results back to the clinical partners. GIFT-Cloud supports collaboration between multiple healthcare and research institutions while satisfying the demands of patient confidentiality, data security and data ownership.},
author = {Doel, Tom and Shakir, Dzhoshkun I. and Pratt, Rosalind and Aertsen, Michael and Moggridge, James and Bellon, Erwin and David, Anna L. and Deprest, Jan and Vercauteren, Tom and Ourselin, S??bastien},
doi = {10.1016/j.cmpb.2016.11.004},
file = {:D$\backslash$:/Mendeley/Doel et al. - 2017 - GIFT-Cloud A data sharing and collaboration platform for medical imaging research.pdf:pdf},
issn = {18727565},
journal = {Computer Methods and Programs in Biomedicine},
keywords = {Anonymisation,Biomedical research,Cross-disciplinary research,Data sharing,Deidentification,Fetal surgery},
pages = {181--190},
publisher = {Elsevier Ireland Ltd},
title = {{GIFT-Cloud: A data sharing and collaboration platform for medical imaging research}},
url = {http://dx.doi.org/10.1016/j.cmpb.2016.11.004},
volume = {139},
year = {2017}
}
@article{Lopez-Garcia2010,
abstract = {One of the main problems in the post-harvest processing of citrus is the detection of visual defects in order to classify the fruit depending on their appearance. Species and cultivars of citrus present a high rate of unpredictability in texture and colour that makes it difficult to develop a general, unsupervised method able of perform this task. In this paper we study the use of a general approach that was originally developed for the detection of defects in random colour textures. It is based on a Multivariate Image Analysis strategy and uses Principal Component Analysis to extract a reference eigenspace from a matrix built by unfolding colour and spatial data from samples of defect-free peel. Test images are also unfolded and projected onto the reference eigenspace and the result is a score matrix which is used to compute defective maps based on the T2 statistic. In addition, a multiresolution scheme is introduced in the original method to speed up the process. Unlike the techniques commonly used for the detection of defects in fruits, this is an unsupervised method that only needs a few samples to be trained. It is also a simple approach that is suitable for real-time compliance. Experimental work was performed on 120 samples of oranges and mandarins from four different cultivars: Clemenules, Marisol, Fortune, and Valencia. The success ratio for the detection of individual defects was 91.5{\%}, while the classification ratio of damaged/sound samples was 94.2{\%}. These results show that the studied method can be suitable for the task of citrus inspection. ?? 2010 Elsevier B.V. All rights reserved.},
author = {L{\'{o}}pez-Garc{\'{i}}a, Fernando and Andreu-Garc{\'{i}}a, Gabriela and Blasco, Jos{\'{e}} and Aleixos, Nuria and Valiente, Jos{\'{e}} Miguel},
doi = {10.1016/j.compag.2010.02.001},
file = {:D$\backslash$:/Mendeley/L{\'{o}}pez-Garc{\'{i}}a et al. - 2010 - Automatic detection of skin defects in citrus fruits using a multivariate image analysis approach.pdf:pdf},
isbn = {0168-1699},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {Automatic Quality Control,Fruit Inspection,Multivariate Image Analysis,Principal Component Analysis,Unsupervised Methods},
number = {2},
pages = {189--197},
title = {{Automatic detection of skin defects in citrus fruits using a multivariate image analysis approach}},
volume = {71},
year = {2010}
}
@article{Polder2014,
abstract = {Tulip breaking virus (TBV) causes severe economic losses in flower bulbs in the Netherlands. To prevent further spread by aphids, the vector of the disease, infected plants must be removed from the field as soon as possible. Until now screening has been carried out by visual inspection in the field. As the availability of human experts is limited there is an urgent need for a rapid, automated and objective method of screening. Based on laboratory experiments, a vision method for use in open fields has been developed. In the period 2009-2012 field trials were carried out and the techniques were tested and improved. During the final evaluation of our system, in the last experiment (2012), the system approached the scores obtained by the experienced crop experts. ?? 2013 IAgrE.},
author = {Polder, Gerrit and van der Heijden, Gerie W A M and van Doorn, Joop and Baltissen, Ton A H M C},
doi = {10.1016/j.biosystemseng.2013.05.010},
file = {:D$\backslash$:/Mendeley/Polder et al. - 2014 - Automatic detection of tulip breaking virus (TBV) intulip fields using machine vision.pdf:pdf},
isbn = {1537-5110},
issn = {15375110},
journal = {Biosystems Engineering},
number = {C},
pages = {35--42},
publisher = {IAgrE},
title = {{Automatic detection of tulip breaking virus (TBV) intulip fields using machine vision}},
url = {http://dx.doi.org/10.1016/j.biosystemseng.2013.05.010},
volume = {117},
year = {2014}
}
@article{Cui2009,
abstract = {Soybean rust, caused by Phakopsora pachyrhizi, is one of the most destructive diseases for soybean production. It often causes significant yield loss and may rapidly spread from field to field through airborne urediniospores. In order to implement timely fungicide treatments for the most effective control of the disease, it is essential to detect the infection and severity of soybean rust. This research explored feasible methods for detecting soybean rust and quantifying severity. In this study, images of soybean leaves with different rust severity were collected using both a portable spectroradiometer and a multispectral CDD camera. Different forms of vegetation indices were used to investigate the possibility of detecting rust infection. Results indicated that both leaf development stage and rust infection severity changed the surface reflectance within a wide band of spectrum. In general, old leaves with most severe rust infection resulted in lowest reflectance. A difference vegetation index (DVI) showed a positive correlation with reflectance differences. However, it lacks solid evidence to identify such reflectance change was solely caused by rust. As an alternative, three parameters, i.e. ratio of infected area (RIA), lesion color index (LCI) and rust severity index (RSI), were extracted from the multispectral images and used to detect leaf infection and severity of infection. The preliminary results obtained from this laboratory-scale research demonstrated that this multispectral imaging method could quantitatively detect soybean rust. Further tests of field scale are needed to verify the effectiveness and reliability of this sensing method to detect and quantify soybean rust infection in real time field scouting.},
author = {Cui, Di and Zhang, Qin and Li, Minzan and Zhao, Youfu and Hartman, Glen L.},
doi = {10.1007/s11694-009-9070-8},
file = {:D$\backslash$:/Mendeley/Cui et al. - 2009 - Detection of soybean rust using a multispectral image sensor.pdf:pdf},
issn = {19327587},
journal = {Sensing and Instrumentation for Food Quality and Safety},
keywords = {Disease area index,Infection level index,Leaf reflectance,Lesion color index,Multispectral image sensor,Soybean rust},
number = {1},
pages = {49--56},
title = {{Detection of soybean rust using a multispectral image sensor}},
volume = {3},
year = {2009}
}
@article{Pourreza2015,
abstract = {Huanglongbing (HLB) or citrus greening is a bacterial infection which is spread by a citrus psyllid. No effective cure for this disease has been reported yet, and the HLB-infected tree will eventually die. Therefore, the infected tree must be detected and removed immediately to stop the spread of the disease. One of the symptoms of HLB is the accumulation of starch which creates blotchy mottles in an asymmetrical pattern on infected citrus leaves. These blotchy mottles symptoms may be confused with the deficiency of certain nutrients such as zinc or magnesium. We showed in a previous study that the unique capability of starch to rotate the polarization planar of light can be employed to identify the HLB-infected citrus leaves and differentiate them from zinc or magnesium deficiency. In this study, a vision sensor was developed for the purpose of real-time HLB detection for use under field conditions. The sensor included a highly sensitive monochrome camera, narrow band high power LEDs, and polarizing filters. The sensor was first tested and calibrated in a simulated field condition in a laboratory. Then, it was tested in a citrus grove. Two simple image descriptors; mean and standard deviation of gray values, were used for the purpose of classification. The results showed that the sensor clearly highlighted the starch accumulation in the HLB-infected leaf and differentiated it from visually analogous symptoms of zinc deficiency. HLB detection accuracies which ranged from 95.5{\%} to 98.5{\%} were achieved during the laboratory and field experiments.},
author = {Pourreza, Alireza and Lee, Won Suk and Ehsani, Reza and Schueller, John K. and Raveh, Eran},
doi = {10.1016/j.compag.2014.11.021},
file = {:D$\backslash$:/Mendeley/Pourreza et al. - 2015 - An optimum method for real-time in-field detection of Huanglongbing disease using a vision sensor.pdf:pdf},
isbn = {0168-1699},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {Citrus greening,Clustering,Disease identification,HLB,Image analysis,Starch accumulation},
number = {1},
pages = {221--232},
publisher = {Elsevier B.V.},
title = {{An optimum method for real-time in-field detection of Huanglongbing disease using a vision sensor}},
url = {http://dx.doi.org/10.1016/j.compag.2014.11.021},
volume = {110},
year = {2015}
}
@article{Zhang2017,
author = {Zhang, Shanwen and Wu, Xiaowei and You, Zhuhong and Zhang, Liqing},
doi = {10.1016/j.compag.2017.01.014},
file = {:D$\backslash$:/Mendeley/Zhang et al. - 2017 - Leaf image based cucumber disease recognition using sparse representation classification.pdf:pdf},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {cucumber disease recognition,cucumber diseased leaf image,sparse representation classification,src},
pages = {135--141},
publisher = {Elsevier B.V.},
title = {{Leaf image based cucumber disease recognition using sparse representation classification}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0168169917300820},
volume = {134},
year = {2017}
}
@article{ArnalBarbedo2013,
abstract = {ABSTRACT: This paper presents a survey on methods that use digital image processing techniques to detect, quantify and classify plant diseases from digital images in the visible spectrum. Although disease symptoms can manifest in any part of the plant, only methods that explore visible symptoms in leaves and stems were considered. This was done for two main reasons: to limit the length of the paper and because methods dealing with roots, seeds and fruits have some peculiarities that would warrant a specific survey. The selected proposals are divided into three classes according to their objective: detection, severity quantification, and classification. Each of those classes, in turn, are subdivided according to the main technical solution used in the algorithm. This paper is expected to be useful to researchers working both on vegetable pathology and pattern recognition, providing a comprehensive and accessible overview of this important field of research.},
author = {{Arnal Barbedo}, Jayme Garcia},
doi = {10.1186/2193-1801-2-660},
file = {:D$\backslash$:/Mendeley/Arnal Barbedo - 2013 - Digital image processing techniques for detecting, quantifying and classifying plant diseases.pdf:pdf},
issn = {2193-1801},
journal = {SpringerPlus},
keywords = {1,2,660,a springeropen journal,bedo springerplus 2013,com,content,http,springerplus,www},
pages = {660},
pmid = {24349961},
title = {{Digital image processing techniques for detecting, quantifying and classifying plant diseases.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3863396{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {2},
year = {2013}
}
@article{Oberti2014,
abstract = {Powdery mildew is a major fungal disease for grapevine ( Vitis vinifera L.) as well as for other important specialty crops, causing severe damage, including yield loss and depreciation of wine or produce quality. This disease is thoroughly controlled by uniform spraying of vineyards with agrochemicals according to a calendar, which can easily result in ten to fifteen fungicide applications in several grapevine-growing areas. Since primary infections are localized in discrete foci rather than being uniformly diffused, there are potential benefits linked to the development of systems able to detect initial infection foci and operate targeted treatments instead of the current homogenous and unselective sprayings. Proximal optical sensing is a major candidate for becoming the preferred technique for identification of foci for powdery mildew in grapevine and other specialty crops, but detection sensitivity of symptoms in the early-middle stage can yield largely limited results due to the combination of small dimensions, low density, and spatial arrangement of thin fungal structures.This study investigated how the detection sensitivity (i.e., the portion of diseased tissue correctly recognized by the system) can be improved, especially for early-middle symptoms by means of sensing measurements carried out from an angle, rather than perpendicularly to the leaf's surface. To this aim, a multispectral imaging approach was applied to 35 grapevine leaves (10 used as calibration and 25 as validation samples) that were imaged at five different view angles from 0?? (camera perpendicular to the leaf surface) up to 75??. Detection sensitivity was evaluated by applying to the validation images an algorithm based on the combination of two spectral indexes. The used algorithm was separately trained basing on the calibration set of images.Overall results indicate that detection sensitivity generally increases as the view angle is increased, with a peak value obtained for images acquired at 60??. In particular, for tissue with early-middle symptoms, the algorithm's sensitivity exhibits a dramatic improvement, from 9{\%} at 0?? up to 73{\%} at 60??.Provided that the adopted training system results in rather homogenous leaves orientation, these findings suggest that field-sensing systems for detecting initial foci of grapevine powdery mildew can achieve improved results by providing the capability of measuring the canopy from a view angle in the range of 40-60??. ?? 2014 Elsevier B.V.},
author = {Oberti, Roberto and Marchi, Massimo and Tirelli, Paolo and Calcante, Aldo and Iriti, Marcello and Borghese, Alberto N.},
doi = {10.1016/j.compag.2014.03.001},
file = {:D$\backslash$:/Mendeley/Oberti et al. - 2014 - Automatic detection of powdery mildew on grapevine leaves by image analysis Optimal view-angle range to increase.pdf:pdf},
isbn = {0168-1699},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {Disease detection,Grapevine,Multispectral imaging,Powdery mildew,Precision pest management,Proximal sensing},
pages = {1--8},
publisher = {Elsevier B.V.},
title = {{Automatic detection of powdery mildew on grapevine leaves by image analysis: Optimal view-angle range to increase the sensitivity}},
url = {http://dx.doi.org/10.1016/j.compag.2014.03.001},
volume = {104},
year = {2014}
}
@article{Zhang2011,
abstract = {Citrus canker, a bacterial disease of citrus tree leaves, causes significant damage to citrus production worldwide. Effective and fast disease detection methods must be undertaken to minimize the losses of citrus canker infection. In this paper, we present a new approach based on global features and zone-based local features to detect citrus canker from leaf images collected in field which is more difficult than the leaf images captured in labs. Firstly, an improved AdaBoost algorithm is used to select the most significant features of citrus lesions for the segmentation of the lesions from their background. Then a canker lesion descriptor is proposed which combines both color and local texture distribution of canker lesion zones suggested by plant phytopathologists. A two-level hierarchical detection structure is developed to identify canker lesions. Thirdly, we evaluate the proposed method and its comparison with other approaches, and the experimental results show that the proposed approach achieves similar classification accuracy as human experts. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Zhang, Min and Meng, Qinggang},
doi = {10.1016/j.patrec.2011.08.003},
file = {:D$\backslash$:/Mendeley/Zhang, Meng - 2011 - Automatic citrus canker detection from leaf images captured in field.pdf:pdf},
isbn = {0167-8655},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Citrus canker detection,Classification,Feature learning,Hierarchical detection,Hue-intensity-saturation,Zone-based texture distribution},
number = {15},
pages = {2036--2046},
publisher = {Elsevier B.V.},
title = {{Automatic citrus canker detection from leaf images captured in field}},
url = {http://dx.doi.org/10.1016/j.patrec.2011.08.003},
volume = {32},
year = {2011}
}
@article{Bock2010,
abstract = {Reliable, precise and accurate estimates of disease severity are important for predicting yield loss, monitoring and forecasting epidemics, for assessing crop germplasm for disease resistance, and for understanding fundamental biological processes including co-evolution. Disease assessments that are inaccurate and/or imprecise might lead to faulty conclusions being drawn from the data, which in turn can lead to incorrect actions being taken in disease management decisions. Plant disease can be quantified in several different ways. This review considers plant disease severity assessment at the scale of individual plant parts or plants, and describes our current understanding of the sources and causes of assessment error, a better understanding of which is required before improvements can be targeted. The review also considers how these can be identified using various statistical tools. Indeed, great strides have been made in the last thirty years in identifying the sources of assessment error inherent to visual rating, and this review highlights ways that assessment errors can be reducedparticularly by training raters or using assessment aids. Lesion number in relation to area infected is known to influence accuracy and precision of visual estimatesthe greater the number of lesions for a given area infected results in more overestimation. Furthermore, there is a widespread tendency to overestimate disease severity at low severities (10{\%}). Both interrater and intrarater reliability can be variable, particularly if training or rating aids are not used. During the last eighty years acceptable accuracy and precision of visual disease assessments have often been achieved using disease scales, particularly because of the time they allegedly save, and the ease with which they can be learned, but recent work suggests there can be some disadvantages to their use. This review considers new technologies that offer opportunity to assess disease with greater objectivity (reliability, precision, and accuracy). One of these, visible light photography and digital image analysis has been increasingly used over the last thirty years, as software has become more sophisticated and user-friendly. Indeed, some studies have produced very accurate estimates of disease using image analysis. In contrast, hyperspectral imagery is relatively recent and has not been widely applied in plant pathology. Nonetheless, it offers interesting and potentially discerning opportunities to assess disease. As plant disease assessment becomes better understood, it is against the backdrop of concepts of reliability, precision and accuracy (and agreement) in plant pathology and measurement science. This review briefly describes these concepts in relation to plant disease assessment. Various advantages and disadvantages of the different approaches to disease assessment are described. For each assessment method some future research priorities are identified that would be of value in better understanding the theory of disease assessment, as it applies to improving and fully realizing the potential of image analysis and hyperspectral imagery.},
author = {Bock, C H and Poole, G H and Parker, P E and Gottwald, T R},
doi = {10.1080/07352681003617285},
file = {:D$\backslash$:/Mendeley/Bock et al. - 2010 - Plant Disease Severity Estimated Visually, by Digital Photography and Image Analysis, and by Hyperspectral Imaging.pdf:pdf},
isbn = {0735-2689},
issn = {0735-2689},
journal = {Critical Reviews in Plant Sciences},
keywords = {aerial-photography,citrus canker,common root-rot,error,horsfall-barratt scale,hyperspectral imagery,image analysis,leaf-spot,plant disease assessment,powdery mildew,remote sensing,variance,vegetation indexes,winter-wheat,yield loss,zea-mays},
number = {2},
pages = {59--107},
title = {{Plant Disease Severity Estimated Visually, by Digital Photography and Image Analysis, and by Hyperspectral Imaging}},
volume = {29},
year = {2010}
}
@article{Kruse2014,
abstract = {Plants exposed to stress due to pollution, disease or nutrient deficiency often develop visible symptoms on leaves such as spots, colour changes and necrotic regions. Early symptom detection is important for precision agriculture, environmental monitoring using bio-indicators and quality assessment of leafy vegetables. Leaf injury is usually assessed by visual inspection, which is labour-intensive and to a considerable extent subjective. In this study, methods for classifying individual pixels as healthy or injured from images of clover leaves exposed to the air pollutant ozone were tested and compared. RGB images of the leaves were acquired under controlled conditions in a laboratory using a standard digital SLR camera. Different feature vectors were extracted from the images by including different colour and texture (spatial) information. Four approaches to classification were evaluated: (1) Fit to a Pattern Multivariate Image Analysis (FPM) combined with T2 statistics (FPM-T2) or (2) Residual Sum of Squares statistics (FPM-RSS), (3) linear discriminant analysis (LDA) and (4) K-means clustering. The predicted leaf pixel classifications were trained from and compared to manually segmented images to evaluate classification performance. The LDA classifier outperformed the three other approaches in pixel identification with significantly higher accuracy, precision, true positive rate and F-score and significantly lower false positive rate and computation time. A feature vector of single pixel colour channel intensities was sufficient for capturing the information relevant for pixel identification. Including neighbourhood pixel information in the feature vector did not improve performance, but significantly increased the computation time. The LDA classifier was robust with 95{\%} mean accuracy, 83{\%} mean true positive rate and 2{\%} mean false positive rate, indicating that it has potential for real-time applications. ?? 2014 Elsevier B.V.},
author = {Kruse, Ole Mathis Opstad and Prats-Montalb{\'{a}}n, Jos{\'{e}} Manuel and Indahl, Ulf Geir and Kvaal, Knut and Ferrer, Alberto and Futsaether, Cecilia Marie},
doi = {10.1016/j.compag.2014.07.010},
file = {:D$\backslash$:/Mendeley/Kruse et al. - 2014 - Pixel classification methods for identifying and quantifying leaf surface injury from digital images.pdf:pdf},
isbn = {0168-1699},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {Classification,Feature extraction,Fit to a pattern model approach (FPM),K-means clustering,Linear discriminant analysis (LDA),Multivariate image analysis (MIA)},
pages = {155--165},
publisher = {Elsevier B.V.},
title = {{Pixel classification methods for identifying and quantifying leaf surface injury from digital images}},
url = {http://dx.doi.org/10.1016/j.compag.2014.07.010},
volume = {108},
year = {2014}
}
@article{Barbedo2016,
abstract = {The problem associated with automatic plant disease identification using visible range images has received considerable attention in the last two decades, however the techniques proposed so far are usually limited in their scope and dependent on ideal capture conditions in order to work properly. This apparent lack of significant advancements may be partially explained by some difficult challenges posed by the subject: presence of complex backgrounds that cannot be easily separated from the region of interest (usually leaf and stem), boundaries of the symptoms often are not well defined, uncontrolled capture conditions may present characteristics that make the image analysis more difficult, certain diseases produce symptoms with a wide range of characteristics, the symptoms produced by different diseases may be very similar, and they may be present simultaneously. This paper provides an analysis of each one of those challenges, emphasizing both the problems that they may cause and how they may have potentially affected the techniques proposed in the past. Some possible solutions capable of overcoming at least some of those challenges are proposed.},
author = {Barbedo, Jayme Garcia Arnal},
doi = {10.1016/j.biosystemseng.2016.01.017},
file = {:D$\backslash$:/Mendeley/Barbedo - 2016 - A review on the main challenges in automatic plant disease identification based on visible range images.pdf:pdf},
isbn = {1537511015302},
issn = {15375110},
journal = {Biosystems Engineering},
keywords = {Automatic identification,Digital image processing,Plant diseases,Visible symptoms},
pages = {52--60},
publisher = {Elsevier Ltd},
title = {{A review on the main challenges in automatic plant disease identification based on visible range images}},
url = {http://dx.doi.org/10.1016/j.biosystemseng.2016.01.017},
volume = {144},
year = {2016}
}

@article{schlichtkrull2017modeling,
  title={Modeling Relational Data with Graph Convolutional Networks},
  author={Schlichtkrull, Michael and Kipf, Thomas N and Bloem, Peter and Berg, Rianne van den and Titov, Ivan and Welling, Max},
  journal={arXiv preprint arXiv:1703.06103},
  year={2017}
}

@article{Aufaure2012,
author = {Aufaure, Amine and Louati, Marie A},
file = {:D$\backslash$:/Mendeley/Graph Aggregation Application to Social Networks.pdf:pdf},
title = {{Graph Aggregation : Application to Social Networks Graph Aggregation Algorithms}},
year = {2012}
}

@article{Khatchadourian2010,
author = {Khatchadourian, Shahan and Consens, Mariano P},
file = {:D$\backslash$:/Mendeley/ExpLOD Summary-Based Exploration of interlinking and RDF usage in the linked open data cloud.pdf:pdf},
pages = {272--287},
title = {{ExpLOD : Summary-Based Exploration of Interlinking and RDF Usage in the Linked Open Data Cloud}},
year = {2010}
}
@article{Ristoski,
author = {Ristoski, Petar and Paulheim, Heiko},
file = {:D$\backslash$:/Mendeley/RDF2Vec RDF Graph Embeddings.pdf:pdf},
keywords = {data mining,graph embeddings,linked open data},
pages = {30},
title = {{RDF2Vec : RDF Graph Embeddings for Data Mining}},
year = {2016}
}


@article{Hassad2017,
author = {Hassad, Sara El and Goasdou{\'{e}}, Fran{\c{c}}ois and Jaudoin, H{\'{e}}l{\`{e}}ne and Commonalities, Learning and Hassad, Sara El},
file = {:D$\backslash$:/Mendeley/Learning Commonalities in RDF.pdf:pdf},
number = {May},
title = {{Learning Commonalities in RDF Sara El Hassad , Fran{\c{c}}ois Goasdou{\'{e}} , H{\'{e}}l{\`{e}}ne Jaudoin To cite this version : HAL Id : hal-01485862 Learning Commonalities in RDF}},
year = {2017}
}
@article{Trisedya2018,
abstract = {A knowledge base is a large repository of facts that are mainly represented as RDF triples, each of which consists of a subject , a predicate (relationship), and an object. The RDF triple representation offers a simple interface for applications to access the facts. However, this representation is not in a natural language form, which is difficult for humans to understand. We address this problem by proposing a system to translate a set of RDF triples into natural sentences based on an encoder-decoder framework. To preserve as much information from RDF triples as possible, we propose a novel graph-based triple encoder. The proposed encoder encodes not only the elements of the triples but also the relationships both within a triple and between the triples. Experimental results show that the proposed en-coder achieves a consistent improvement over the baseline models by up to 17.6{\%}, 6.0{\%}, and 16.4{\%} in three common metrics BLEU, METEOR, and TER, respectively.},
author = {Trisedya, Bayu Distiawan and Qi, Jianzhong and Zhang, Rui and Wang, Wei},
file = {:D$\backslash$:/Mendeley/GTR-LSTM A Triple Encoder for Sentence Generation from RDF Data.pdf:pdf},
journal = {Proceedings of ACL},
pages = {1627--1637},
title = {{GTR-LSTM: A Triple Encoder for Sentence Generation from RDF Data}},
url = {http://aclweb.org/anthology/P18-1151},
year = {2018}
}
@article{Schlichtkrull2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1703.06103v4},
author = {Schlichtkrull, Michael and Kipf, Thomas N and Bloem, Peter and Titov, Ivan and Welling, Max},
eprint = {arXiv:1703.06103v4},
file = {:D$\backslash$:/Mendeley/Modeling Relational Data with Graph Convolutional Networks.pdf:pdf},
number = {1},
title = {{Modeling Relational Data with Graph Convolutional Networks}},
year = {2017}
}
@article{Jozefowicz2015,
author = {Jozefowicz, Rafal and Com, Ilyasu Google},
file = {:D$\backslash$:/Mendeley/RNN{\_}An Empirical Exploration of Recurrent Network Architectures.pdf:pdf},
title = {{An Empirical Exploration of Recurrent Network Architectures}},
volume = {37},
year = {2015}
}




